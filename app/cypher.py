class Cypher:
	def __init__(self):
		pass
	# user procedures
	allowed_emails = (
		' MATCH '
		'	(e: Emails) '
		' RETURN '
		'	e.allowed '
	)
	user_allowed_emails = (
		' MATCH '
		'	(u:User) '
		' WITH '
		'	COLLECT (DISTINCT u.email) as registered_emails '
		' MATCH '
		'	(user:User {'
		'		username_lower : toLower(trim($username)) '
		'	}) '
		'	-[: SUBMITTED]->(: Submissions) '
		'	-[: SUBMITTED]->(e: Emails) '
		' RETURN '
		'	FILTER (n in e.allowed WHERE NOT n in registered_emails) as user_allowed '
	)
	email_find = (
		' MATCH '
		'	(user: User { '
		'		email: toLower(trim($email)) '
		'	}) '
		' RETURN '
		'	user '
	)
	confirm_email = (
		' MATCH '
		'	(user: User { '
		'		email: toLower(trim($email)) '
		'	}) '
		' SET '
		'	user.confirmed = true '
	)
	user_find = (
		' MATCH '
		'	(user: User) '
		'		WHERE '
		'			user.username_lower = toLower($username) '
		'		OR '
		'			user.email = toLower(trim($email)) '
		' RETURN '
		'	user '
	)
	username_find = (
		' MATCH '
		'	(user: User { '
		'		username_lower: toLower($username)'
		'	}) '
		' RETURN '
		'	user '
	)
	user_affiliations = (
		' MATCH '
		'	(u: User { '
		'		username_lower: toLower($username) '
		'	}) '
		'	-[a: AFFILIATED]->(p: Partner) '
		' OPTIONAL MATCH '
		'	(p)<-[: AFFILIATED {admin: true}]-(admin: User) '
		' RETURN '
		'	p.name , '
		'	p.fullname , '
		'	a.confirmed as confirmed, '
		'	a.data_shared as data_shared , '
		'	admin.email as admin_email'
	)
	add_affiliations = (
		' UNWIND '
		'	$partners as partner '
		' 	MATCH '
		'		(u:User { '
		'			username_lower: toLower(trim($username)) '
		'		}), '
		'		(p:Partner { '
		'			name_lower: toLower(trim(partner)) '
		'		}) '
		' 	MERGE '
		'		(u)-[a: AFFILIATED { '
		'			data_shared: false, '
		'			admin: false, '
		'			confirm_timestamp: [], '
		'			confirmed: false '
		' 		}]->(p) '
		' 	ON CREATE SET '
		'		a.add_timestamp = timestamp() '
		' 	RETURN '
		'		p.name '
	)
	remove_affiliations = (
		' UNWIND '
		'	$partners as partner '
		' 	MATCH '
		'		(u:User { '
		'			username_lower: toLower(trim($username)) '
		'		 }) '
		'		-[a:AFFILIATED { '
		'			data_shared: false '
		'		}]->(p: Partner {'
		'			name_lower: toLower(trim(partner)) '
		'		}) '
		' 	WHERE '
		'		size(a.confirm_timestamp) = 0 '
		' 	DELETE '
		'		a '
		' 	RETURN p.name '
	)
	password_reset = (
		' MATCH '
		'	(user: User { '
		'		email : toLower(trim($email)) '
		' 	}) '
		' SET user.password = $password '
	)
	user_register = (
		# This is a little cautious using merge to prevent overwriting a user profile if it is called in error
		' MATCH '
		'	(partner:Partner {'
		'		name_lower: toLower(trim($partner)) '
		'	}) '
		' MERGE '
		'	(user:User { '
		'		username_lower: toLower(trim($username)) '
		'	}) '
		'	ON CREATE SET '
		'		user.username = trim($username), '
		'		user.password = $password, ' 
		'		user.email = toLower(trim($email)), '
		'		user.name = $name, '
		'		user.time = timestamp(), '
		'		user.access = ["user"], '
		'		user.confirmed = false, '
		'		user.found = false '
		'	ON MATCH SET '
		'		user.found = TRUE '
		' WITH '
		'	user, partner '	
		' WHERE '
		'	user.found = false '
		' CREATE '
		'	(user)-[r: AFFILIATED { '
		'		data_shared: true, '
		'		confirmed: false, '
		'		confirm_timestamp: [], '
		'		admin: false '				
		'	}]->(partner), '
		'	(user)-[: SUBMITTED]->(sub: Submissions), '
		'		(sub)-[: SUBMITTED]->(: Emails {allowed :[]}),'
		'		(sub)-[: SUBMITTED]->(locations: Locations), '
		'			(locations)-[: SUBMITTED]->(: Countries), '
		'			(locations)-[: SUBMITTED]->(: Regions), '
		'			(locations)-[: SUBMITTED]->(: Farms), '
		'		(sub)-[:SUBMITTED]->(items: Items), '
		'			(items)-[: SUBMITTED]->(: Fields), '
		'			(items)-[: SUBMITTED]->(: Blocks), '
		'			(items)-[: SUBMITTED]->(: Trees), '
		'			(items)-[: SUBMITTED]->(: Samples), '
		'		(sub)-[:SUBMITTED]->(: Records) '
	)
	add_allowed_email = (
		' MATCH '
		'	(all: Emails) '
		' WITH '
		'	all.allowed as allowed_emails '
		' UNWIND '
		'	allowed_emails as email '
		' WITH '
		'	COLLECT(DISTINCT email) as set '
		' WHERE '
		'	NOT toLower(trim($email)) IN set '
		' MATCH '
		'	(:User { '
		'		username_lower: toLower(trim($username)) '
		' 	}) '
		'	-[:SUBMITTED]->(: Submissions) '
		'	-[:SUBMITTED]->(e: Emails) '
		' SET e.allowed = e.allowed + [toLower(trim($email))] '
		' RETURN toLower(trim($email)) '
	)
	remove_allowed_email = (
		' MATCH '
		'	(:User { '
		'		username_lower: toLower(trim($username)) '
		' 	}) '
		'	-[:SUBMITTED]->(: Submissions) '
		'	-[:SUBMITTED]->(e: Emails) '
		' WITH e, extract(x in $email | toLower(trim(x))) as emails'
		' SET e.allowed = FILTER (n in e.allowed WHERE NOT n IN emails) '
		' RETURN emails '
	)
	user_del = (
		' MATCH '
		'	(u:User { '
		'		email: toLower(trim($email)), '
		'		confirmed: false '
		'	}) '
		' OPTIONAL MATCH '
		'	(u)-[:SUBMITTED*..3]->(n) '
		' DETACH DELETE '
		' u,n '
	)
	partner_admin_users = (
		' MATCH '
		'	(:User { '
		'		username_lower: toLower(trim($username)) '
		' 	}) '
		'	-[: AFFILIATED { '
		'		admin: true '
		'	}]->(p:Partner) '
		' WITH p '
		' MATCH '
		'	(p)<-[a:AFFILIATED]-(u:User) ' 
		' RETURN { '
		'	Username: u.username, '
		'	Email: u.email, '
		'	Name: u.name, '
		'	Partner: p.name, '
		'	PartnerFullName: p.fullname, '
		'	Confirmed: a.confirmed '
		' } '
	)
	global_admin_users = (
		' MATCH '
		'	(u:User)-[a:AFFILIATED]->(p:Partner) '
		' RETURN { '
		'	Username : u.username, '
		'	Email : u.email, '
		'	Name : u.name, '
		'	Partner : p.name, '
		'	PartnerFullName : p.fullname, '
		'	Confirmed : a.confirmed '
		' } '
	)
	# these functions toggle the confirmed status so do both confirm/un-confirm operations
	partner_confirm_users = (
		' MATCH '
		'	(user:User { '
		'		username_lower: toLower(trim($username)) '
		' 	}) '
		'	-[:AFFILIATED {admin : true}]->(p:Partner) '
		' WHERE '
		'	"partner_admin" in user.access'
		' MATCH '
		'	(p)<-[a:AFFILIATED]-(u:User) '
		' UNWIND '
		'	$confirm_list as confirm '
		' 	WITH '
		'		p,a,u '
		' 	WHERE '
		'		p.name_lower = toLower(trim(confirm["partner"])) '
		' 	AND '
		'		u.username_lower = toLower(trim(confirm["username"])) '
		' 	SET '
		'		a.confirmed = NOT a.confirmed, '
		'		a.confirm_timestamp = a.confirm_timestamp + timestamp() '
		' 	RETURN u.name '
	)
	global_confirm_users = ( 
		' MATCH '
		'	(p:Partner)<-[a:AFFILIATED]-(u:User) '
		' UNWIND '
		'	$confirm_list as confirm '
		' WITH '
		'	p,a,u '
		' WHERE '
		'	p.name_lower = toLower(trim(confirm["partner"])) '
		' AND '
		'	u.username_lower = toLower(trim(confirm["username"])) '
		' SET '
		'	a.confirmed = NOT a.confirmed, '
		'	a.confirm_timestamp = a.confirm_timestamp + timestamp() '
		' RETURN u.name '
	)
	partner_admins = (
		' MATCH '
		'	(u:User)-[a:AFFILIATED]->(p:Partner) '
		' RETURN { '
		'	Username : u.username, '
		'	Email : u.email, '
		'	Name : u.name, '
		'	Partner : p.name, '
		'	PartnerFullName : p.fullname, '
		'	Confirmed : a.admin '
		' } '
	)
	confirm_admins = (
		' MATCH '
		'		(p:Partner)<-[a:AFFILIATED]-(u:User) '
		' UNWIND $admins as admin '
		' 	WITH '
		'		p,a,u '
		' 	WHERE '
		'		p.name_lower = toLower(trim(admin["partner"])) '
		' 	AND '
		'		u.username_lower = toLower(trim(admin["username"])) '
		' 	SET '
		'		a.admin = NOT a.admin '
		'	WITH u '
		'		MATCH (u)-[a:AFFILIATED]->(:Partner) '
		'		WITH u, collect(a.admin) as admin_rights '
		'		set u.access = CASE '
		'			WHEN true IN admin_rights '
		'			THEN ["user","partner_admin"] '
		'			ELSE ["user"] '
		'			END '
		' 	RETURN '
		'		u.name '
	)

	# Upload procedures
	upload_check_value = (
		# make sure that all the entries match accepted entries
		# handles empty items and white space
		# forces strings to lower case and float/integer types
		# removes % symbols
		# ! ensure to declare feature (as node) and value (from file) before including
		' CASE '
		'	WHEN feature.format = "multicat" '
		'		THEN CASE '
		'			WHEN size(FILTER (n in split(value, ":") WHERE size(n) > 0)) '
		'				= size(FILTER (n in split(value, ":") WHERE toLower(trim(n)) in '
		'					EXTRACT(item in feature.category_list | toLower(item)))) '
		'			THEN trim(value) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "categorical" '
		'		THEN CASE '
		'			WHEN toLower(trim(value)) in extract(item in feature.category_list | toLower(item)) '
		'				THEN trim(value) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "text" '
		'		THEN CASE '
		'			WHEN feature.name_lower CONTAINS "assign to" '
		'				THEN CASE '
		'					WHEN size(split(value, "," )) = size(filter(x in split(value, ",") where toInteger(trim(x)) IS NOT NULL)) '
		'					THEN value '
		'					ELSE Null '
		'					END '
		'			WHEN feature.name_lower = "synthetic fertiliser n:p:k ratio" '
		'				THEN CASE '
		'					WHEN size(split(value, ":")) = 3 '
		'					AND toFloat(trim(split(value, ":")[0])) IS NOT NULL '
		'					AND toFloat(trim(split(value, ":")[1])) IS NOT NULL '
		'					AND toFloat(trim(split(value, ":")[2])) IS NOT NULL '
		'						THEN trim(value) '
		'					ELSE Null '
		'					END '
		'			WHEN feature.name contains "time" '
		'				THEN CASE '
		'					WHEN size(split(value, ":")) = 2 '
		'					AND size(split(value, ":")[0]) <= 2 '
		'					AND toInteger(trim(split(value, ":")[0])) <=24 '
		'					AND toInteger(trim(split(value, ":")[0])) >= 0 '
		'					AND size(split(value, ":")[1]) <= 2 '
		'					AND toInteger(trim(split(value, ":")[1])) < 60 '
		'					AND toInteger(trim(split(value, ":")[1])) >= 0 '
		'						THEN trim(value) '
		'					ELSE Null '
		'					END '
		'			ELSE '
		'				toString(value) '
		'			END '
		'	WHEN feature.format = "percent" '
		'		THEN CASE '
		'			WHEN toFloat(replace(value, "%", "")) IS NOT NULL '
		'				THEN toFloat(replace(value, "%", "")) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "counter" '
		'		THEN CASE '
		'			WHEN toInteger(value) IS NOT NULL '
		'				THEN toInteger(value) '
		'			ELSE '
		'				Null '
		'			END '
		'	WHEN feature.format = "numeric" '
		'		THEN CASE '
		'			WHEN toFloat(value) IS NOT NULL '
		'				THEN toFloat(value) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "boolean" '
		'		THEN CASE '
		'			WHEN toLower(value) in ["yes","y"] '
		'				THEN True '
		'			WHEN toLower(value) in ["no","n"] '
		'				THEN False '
		'			WHEN toBoolean(value) IS NOT NULL '
		'				THEN toBoolean(value) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "location" '
		'		THEN CASE '
		'			WHEN size(split(value, ";")) = 2 '
		'			AND toFloat(trim(split(value, ";")[0])) IS NOT NULL '
		'			AND toFloat(trim(split(value, ";")[1])) IS NOT NULL '
		'				THEN trim(value) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "date" '
		'		THEN CASE '
		'			WHEN size(split(value, "-")) = 3 '
		'			AND size(trim(split(value, "-")[0])) = 4 '
		'			AND size(trim(split(value, "-")[1])) <= 2 '
		'			AND size(trim(split(value, "-")[1])) >= 1 '
		'			AND toInteger(trim(split(value, "-")[1])) >= 1 '
		'			AND toInteger(trim(split(value, "-")[1])) <= 12 '
		'			AND size(trim(split(value, "-")[2])) <= 2 '
		'			AND size(trim(split(value, "-")[2])) >= 1 '
		'			AND toInteger(trim(split(value, "-")[1])) >= 1 '
		'			AND toInteger(trim(split(value, "-")[1])) <= 31 '
		'			THEN '
		'				trim(value) '
		'			ELSE '
		'				Null '
		'			END '
		'	ELSE Null '
		'	END '
	)
	shared_upload_code = (
		' FOREACH (n in CASE '
		'	WHEN level = "field" '
		'		THEN [1] ELSE [] END | '
		'			MERGE '
		'				(item)<-[: FOR_ITEM]-(:ItemFeature)-[: FOR_FEATURE]->(feature) '
		' ) '
		' FOREACH (n in CASE '
		'	WHEN level in ["block", "tree", "sample"] '
		'		THEN [1] ELSE [] END | '
		'			MERGE '
		'				(field)<-[: FROM_FIELD]-(field_feature: FieldFeature)-[: FOR_FEATURE]->(feature) '
		'			MERGE '
		'				(item)<-[: FOR_ITEM]-(:ItemFeature)-[: FOR_FEATURE]->(field_feature) '
		' ) '
		# get rid of some of the optional matches since they are no longer needed
		' WITH '
		'	field, item, feature, level, time, start, end, replicate, '
		'	person, '
		'	location, timestamp, text_time, text_date, text_start_time, text_start_date, text_end_time, text_end_date, '
		+ upload_check_value + ' AS value WHERE value IS NOT NULL '
		# get the user submission tracking nodes
		' MATCH '
		'	(:User { '
		'		username_lower : toLower(trim($username))'
		'	}) '
		'	-[: SUBMITTED]->(: Submissions) '
		'	-[: SUBMITTED]->(data_sub: Records) '
		# and the item/feature node
		' MATCH '
		' (item)<-[: FOR_ITEM]-(item_feature: ItemFeature)-[ :FOR_FEATURE*..2]->(feature) '
		' OPTIONAL MATCH '
		' (field_feature: FieldFeature)<-[: FOR_FEATURE]-(item_feature) '
		# Perform optional matches so can modify relationships for some features
		# In case feature "assign to block"
		# if has block assignment find current IS_IN block-trees rel (to remove current flag) and counter (to decrement)
		' OPTIONAL MATCH '
		'	(item) '
		'	-[is_in_block_current:IS_IN {current: True}]->(: BlockTrees) '
		'	<-[:FOR]-(block_counter_current:Counter) '
		# and then find the block by uid for update of IS_IN block-trees rel and counter 
		' OPTIONAL MATCH '
		'	(block_counter_update: Counter) '
		'	-[: FOR]->(block_trees_update: BlockTrees) '
		'	-[: IS_IN]->(: Block {id: value}) '
		'	-[: IS_IN]->( :FieldBlocks)'
		'	-[: IS_IN]->(field) '
		# Using many with statements around long optional match blocks
		# otherwise there is a database error I haven't diagnosed
		' WITH '
		'	field, item, feature, level, item_feature, coalesce(field_feature, item_feature) as field_feature, '
		'	time, start, end, '
		'	location, timestamp, text_time, text_date, text_start_time, text_start_date, text_end_time, text_end_date, '
		'	replicate, value, person, '
		'	data_sub, '
		'	is_in_block_current, block_counter_current, block_trees_update, block_counter_update '		   
		# In case sample feature "assign to trees" 
		# should only work for samples currently registered to a field
		# find current assignment
		' OPTIONAL MATCH '
		'	(item)-[from_current: FROM]->(:ItemSamples)-[:FROM]->(field) '
		# and update tree by uid
		' OPTIONAL MATCH '
		'	(tree_update: Tree)-[: IS_IN*2]->(field) '
		'	WHERE tree_update.id in value '
		' WITH '
		'	field, item, feature, level, item_feature, field_feature, '
		'	time, start, end, '
		'	location, timestamp, text_time, text_date, text_start_time, text_start_date, text_end_time, text_end_date, '
		'	replicate, value, person, '
		'	data_sub, '
		'	is_in_block_current, block_counter_current, block_trees_update, block_counter_update, '
		'	from_current, '
		'	collect(tree_update) as tree_update '
		# variety matching		
		' OPTIONAL MATCH '
		'	(: Variety)'
		'	<-[:OF_VARIETY]-(: FieldVariety) '
		'	<-[of_variety_current:OF_VARIETY]-(item) '
		' OPTIONAL MATCH '
		'	(variety_update: Variety) '
		'	WHERE '
		'		toLower(variety_update.name_lower) = toLower(value) '
		'	OR ('
		'		variety_update.code IS NOT NULL '
		'		AND '
		'		toLower(variety_update.code) = toLower(value) '
		'	) '
		# need to check for conflicts with existing records before merger due to condition flexible start/end
		' MERGE '
		'	(r:Record { '
		'		time : CASE WHEN time IS NULL THEN False ELSE time END, '
		'		start: CASE WHEN start IS NULL THEN False ELSE start END, '
		'		end: CASE WHEN end IS NULL THEN False ELSE end END, '
		'		replicate: CASE WHEN replicate IS NULL THEN 1 ELSE replicate END '
		'	}) '
		'	-[:RECORD_FOR]->(item_feature) '
		'	ON MATCH SET '
		'		r.found = True '
		'	ON CREATE SET '
		'		r.found = False, '
		'		r.location = location, '
		'		r.person = person, '
		'		r.timestamp = timestamp, '
		'		r.text_date = text_date, '
		'		r.text_time = text_time, '
		'		r.text_start_date = text_start_date, '
		'		r.text_start_time = text_start_time, '
		'		r.text_start_date = text_end_date, '
		'		r.text_start_time = text_end_time, '					   
		'		r.value = CASE '
		' 			WHEN feature.format <> "multicat" THEN value '
		'			ELSE extract(i in FILTER (n in split(value, ":") WHERE  size(n) > 0 )| toLower(trim(i)))'
		'			END '
		# additional statements to occur when new data point
		' FOREACH (n IN CASE '
		'		WHEN r.found = False '
		'			THEN [1] ELSE [] END | '
		# track user submissions through /User/FieldFeature container
		'				MERGE '
		'					(data_sub)'
		'					-[:SUBMITTED]->(uff:UserFieldFeature) '
		'					-[:CONTRIBUTED]->(field_feature) '
		# then finally the data with a timestamp
		'				MERGE '
		'					(uff)-[s1:SUBMITTED]->(r) '
		'					ON CREATE SET '
		'						s1.time = timestamp() '
		' ) '
		# Now update relationship feature values
		# "assign to block" 
		' FOREACH (n IN CASE '
		'	WHEN r.value = value '
		'	AND feature.name_lower = "assign to block" '
		'	AND block_trees_update IS NOT NULL '
		'	THEN [1] ELSE [] END | '
		# link tree to block (and adjust number of trees in block with counter)
		'		MERGE '
		'			(item)-[s1:IS_IN]->(block_trees_update) '
		'		ON CREATE SET '
		'			s1.time = timestamp(), '
		'			s1.user = $username, '
		'			s1.from = "upload" '
		'		SET '
		'			block_counter_current._LOCK_ = true, '
		'			block_counter_update._LOCK_ = true '
		'		SET '
		'			is_in_block_current.current = False, '
		'			s1.current = True, '
		'			block_counter_current.count = block_counter_current.count - 1, '
		'			block_counter_update.count = block_counter_update.count + 1 '
		'		REMOVE '
		'			block_counter_current._LOCK_, '
		'			block_counter_update._LOCK_ '
		' ) '
		# "assign to trees"
		# In this case samples are either:
		#   - registered to a field where the relationship is preserved through the UID
		#      - can't update from a tree '
		#      - the submitting user and time is stored in the user_samples relationship
		#   - registered to trees adjusted through record submission, also recorded.
		# so we can safely delete this relationship and just create the new one.
		' FOREACH (n IN CASE '
		'	WHEN r.value = value '
		'	AND feature.name_lower = "assign to trees" '
		'	AND tree_update IS NOT NULL '
		'	THEN [1] ELSE [] END | '
		'		DELETE from_current '
		'		FOREACH (sampled_tree IN tree_update | '					   
		'			MERGE '
		'				(item_samples: ItemSamples)-[: FROM]->(sampled_tree) '
		'			MERGE '
		'				(item)-[s1: FROM]->(item_samples) '
		'			ON CREATE SET '
		'				s1.time = timestamp(), '
		'				s1.user = $username '
		'		) '
		' ) '
		# update variety rels
		' FOREACH (n IN CASE '
		'	WHEN r.value = value '
		'	AND feature.name_lower contains "variety" '
		'	AND variety_update IS NOT NULL '
		'	THEN [1] ELSE [] END | '
		'		DELETE of_variety_current '
		'		MERGE '
		'			(field)'
		'			-[: CONTAINS_VARIETY]->(fv: FieldVariety) '
		'			-[: OF_VARIETY]->(variety_update) '
		'		MERGE '
		'			(item)-[s1: OF_VARIETY]->(fv) '
		'		ON CREATE SET '
		'			s1.time = timestamp(), '
		'			s1.user = $username '
		' ) '
		# now set item properties
		# if custom ID set custom id property. 
		' SET item.custom_id = CASE '
		'	WHEN r.value = value '
		'	AND r.value IS NOT NULL '
		'	AND feature.name_lower = "assign custom id" '
		'	THEN toString(r.value) '
		'	ELSE item.custom_id '
		'	END '
		' WITH '
		'	item, feature, value, r '
		' MATCH '
		'	(partner:Partner) '
		'	<-[:AFFILIATED {data_shared: True}]-(user:User)'
		'	-[:SUBMITTED*..7]->()-[submitted:SUBMITTED]->(r) '
		# need to check for permissions for values that didn't merge to provide filtered feedback
		# and optionally roll back if existing records overlap without access confirmed.
		' OPTIONAL MATCH '
		'	(p)<-[access: AFFILIATED {confirmed: True}]-(:User {username_lower:toLower(trim($username))}) '
		# And give the user feedback on their submission
		' RETURN { '
		'	found: r.found, '
		'	submitted_by: user.name, '
		'	submitted_at: submitted.time, '
		'	value: r.value, '
		'	uploaded_value: value, '
		'	uid: item.uid, '
		'	feature: feature.name, '
		'	`Time/Period`: coalesce('
		'		CASE WHEN r.time <> False THEN r.time Else Null END,'
		'		[r.start, r.end]'
		'	), '
		#'	time: r.time, '
		#'	start: r.start, '
		#'	end: r.end, '
		'	access: access.confirmed, '
		'	partner: partner.name, '
		'	timestamp: r.timestamp, '
		'	text_date: r.text_date, '
		'	text_time: r.text_time, '
		'	text_start_date: r.text_start_date, '
		'	text_start_time: r.text_start_time, '
		'	text_end_date: r.text_end_date, '
		'	text_end_time: r.text_end_time '
		' } '
	)
	# generic upload to handle mixed UID (multiple levels) in csv in database format
	upload_fb_check = (
	#	' LOAD CSV WITH HEADERS FROM $filename as csvLine '
	#	' WITH '
	#	'	split(trim(toUpper(csvLine.uid)), ".")[0] as uid, '
	#	'	trim(toLower(csvLine.trait)) as trait_name_lower, '
	#	'	trim(csvLine.value) as value '
	#	# Identify the items and traits assessed
	#	' OPTIONAL MATCH '
	#	'	(item: Item { '
	#	'		uid: '
	#	'			CASE '
	#	'				WHEN size(split(uid, "_")) = 1 '
	#	'					THEN toInteger(uid) '
	#	'				ELSE '
	#	'					uid '
	#	'				END '
	#	'	})'
	#	' OPTIONAL MATCH '
	#	'	(trait: Trait { '
	#	'		name_lower: trait_name_lower, '
	#	'		level: '
	#	'			CASE '
	#	'				WHEN split(uid, "_")[1] IS NULL '
	#	'					THEN "field" '
	#	'				WHEN left(split(uid, "_")[1],1) = "B" '
	#	'					THEN "block" '
	#	'				WHEN left(split(uid, "_")[1],1) = "T" '
	#	'					THEN "tree" '
	#	'				WHEN left(split(uid, "_")[1],1) = "R" '
	#	'					THEN "branch" '
	#	'				WHEN left(split(uid, "_")[1],1) = "L" '
	#	'					THEN "leaf" '
	#	'				WHEN left(split(uid, "_")[1],1) = "S" '
	#	'					THEN "sample" '
	#	'				END '
	#	'	}) '
	#	' 	WITH '
	#	'		CASE WHEN item IS NULL THEN False ELSE True END as item, '
	#	'		CASE WHEN trait IS NULL THEN False ELSE trait.name_lower END as trait, '
	#	'		trait.format as format, '
	#	'		trait.category_list as category_list, '
	#	'		CASE WHEN item IS NOT NULL AND trait IS NOT NULL '
	#	'			THEN '
	#	'				CASE WHEN ' + upload_check_value +
	#	'				IS NULL THEN False ELSE True END '
	#	'			ELSE False '
	#	'			END '
	#	'			as value '
	#	' RETURN { '
	#	'	uid: item, '
	#	'	trait: trait, '
	#	'	format: format,'
	#	'	category_list: category_list,'
	#	'	value: value '
	#	' } '
	)
	upload_fb = (
	#	# load in the csv
	#	' LOAD CSV WITH HEADERS FROM $filename as csvLine '
	#	' WITH '
	#	'	trim(csvLine.location) as location, '
	#	'	trim(csvLine.person) as person, '
	#	'	split(trim(toUpper(csvLine.uid)), ".")[0] as uid, '
	#	'	split(trim(toUpper(csvLine.uid)), ".")[1] as replicate, '
	#	'	toLower(trim(csvLine.trait)) as trait_name_lower, '
	#	'	csvLine.timestamp as timestamp, '
	#	'	trim(csvLine.value) as value, '
	#	'	apoc.date.parse(csvLine.timestamp, "ms", "yyyy-MM-dd HH:mm:sszzz") as time '
	#	# Identify the items and traits assessed
	#	' MATCH '
	#	'	(field:Field { '
	#	'		uid: toInteger(split(uid, "_")[0]) '
	#	'	}), '
	#	'	(item: Item { '
	#	'		uid: '
	#	'			CASE '
	#	'				WHEN size(split(uid, "_")) = 1 '
	#	'					THEN toInteger(uid) '
	#	'				ELSE '
	#	'					uid '
	#	'				END '
	#	'	}), '
	#	'	(trait: Trait { '
	#	'		name_lower: trait_name_lower, '
	#	'		level: '
	#	'			CASE '
	#	'				WHEN split(uid, "_")[1] IS NULL '
	#	'					THEN "field" '
	#	'				WHEN left(split(uid, "_")[1],1) = "B" '
	#	'					THEN "block" '
	#	'				WHEN left(split(uid, "_")[1],1) = "T" '
	#	'					THEN "tree" '
	#	'				WHEN left(split(uid, "_")[1],1) = "R" '
	#	'					THEN "branch" '
	#	'				WHEN left(split(uid, "_")[1],1) = "L" '
	#	'					THEN "leaf" '
	#	'				WHEN left(split(uid, "_")[1],1) = "S" '
	#	'					THEN "sample" '
	#	'				END '
	#	'	}) '
	#	'	WHERE size(value) > 0 '
	#	' WITH '
	#	'	field, item, trait, '
	#	'	person, time, replicate, '
	#	'	value, '
	#	# this is unique to FB uploads
	#	'	timestamp, '
	#	'	location, '
	#	# the following are nulls where table has values to allow shared code between formats
	#	'	null as text_time, '
	#	'	null as text_date '
	#	'	WHERE time IS NOT NULL '
	#	+ shared_upload_code
	)
	# Upload Table procedures
	upload_table_check = (
		' LOAD CSV WITH HEADERS FROM $filename as csvLine '
		' WITH '
		'	csvLine, '
		'	toInteger(csvLine.row_index) as row_index, '
		'	split(trim(toUpper(csvLine.uid)), ".")[0] as uid, '
		# start time from start date and start time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.date, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.date, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.time, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.time, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.time, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.time, " ", "") '
		'			ELSE '
		'				"12:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as time, '
		# start time from start date and start time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`start date`, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.`start date`, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`start time`, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.`start time`, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.`start time`, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.`start time`, " ", "") '
		'			ELSE '
		'				"00:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as start, '
		# end time from end date and end time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`end date`, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.`end date`, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`end time`, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.`end time`, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.`end time`, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.`end time`, " ", "") '
		'			ELSE '
		'				"24:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as end '
		' OPTIONAL MATCH  '
		'	(item: Item { '
		'		uid: '
		'			CASE '
		'				WHEN size(split(uid, "_")) = 1 '
		'					THEN toInteger(uid) '
		'				ELSE '
		'					toUpper(uid) '
		'				END '
		'	}) '
		' UNWIND $features as feature_name '
		'	OPTIONAL MATCH '
		'		(:RecordType {'
		'			name_lower: '
		'				CASE WHEN time IS NOT NULL THEN "trait" ELSE "condition" END '
		'		}) '
		'		<-[:OF_TYPE]-(feature: Feature { '
		'			name_lower: toLower(feature_name) '
		'		})-[:AT_LEVEL]->(:ItemLevel { '
		'			name_lower: '
		'				CASE '
		'					WHEN split(uid, "_")[1] IS NULL '
		'						THEN "field" '
		'					WHEN toUpper(left(split(uid, "_")[1],1)) = "B" '
		'						THEN "block" '
		'					WHEN toUpper(left(split(uid, "_")[1],1)) = "T" '
		'						THEN "tree" '
		'					WHEN toUpper(left(split(uid, "_")[1],1)) = "S" '
		'						THEN "sample" '
		'					END '
		'		}) '
		'	WITH '
		'		row_index, '
		'		item, feature, feature_name, time, start, end, '
		'		csvLine[feature_name] as value WHERE trim(csvLine[feature_name]) <> ""'
		'	OPTIONAL MATCH '
		'		(item)<-[:FOR_ITEM]-(if: ItemFeature)-[:FOR_FEATURE*..2]->(feature), '
		'		(if)<-[:RECORD_FOR]-(r: Record) '
		'		<-[s: SUBMITTED]-(: UserFieldFeature) '
		'		<-[: SUBMITTED]-(: Records) '
		'		<-[: SUBMITTED]-(: Submissions) '
		'		<-[: SUBMITTED]-(u: User) '
		'		-[:AFFILIATED {data_shared: true}]->(p:Partner) '
		'	OPTIONAL MATCH '
		'		(p)<-[a: AFFILIATED]-(: User {username_lower: toLower($username)}) '
		# set lock on ItemCondition node and only unlock after merge or result
		# this is either rolled back or set to false on subsequent merger, 
		# prevents conflicts (per item/feature) emerging from race condition 
		# TODO Consider the impact/need for establishing this write lock and ensure set to false in subsequet merger
		# there may be implications with multiple rows for the same item in a single file
		# but need to check if this is currently permitted
		# '	SET if._LOCK_ = True '
		'	WITH '
		'		row_index, '
		'		feature_name, '
		'		item, feature, time, start, end, '
		+ upload_check_value +
		'		AS value, '
		'		CASE WHEN r.time <> False THEN r.time ELSE Null END AS existing_time, '
		'		CASE WHEN r.start <> False THEN r.start ELSE Null END AS existing_start, '
		'		CASE WHEN r.end <> False THEN r.end ELSE Null END AS existing_end, '
		'		CASE '
		'			WHEN a.confirmed '
		'			THEN r.value '
		'			ELSE CASE '
		'				WHEN r IS NOT NULL '
		'				THEN "ACCESS DENIED" '
		'				ELSE null '
		'				END '
		'			END AS existing_value, '
		'		s.time AS submitted_at, '
		'		CASE WHEN a.confirmed THEN u.name ELSE p.name END AS user, '
		'		a.confirmed AS access '
		'	WHERE '
		'	( '
		'		item IS NULL '
		'		OR '
		'		feature IS NULL '
		'		OR '
		'		value IS NULL '
		'	) OR ( '
		# condition conflicts
		'	(	'
		'		a.confirmed <> True '
		'		OR'
		'		r.value <> value '
		'	) AND (( '
		# for traits just check for same time
		#  - if submission is condition (i.e. time is Null) then will always equate to null
		#  - if existing record is condition then r.time is False so will always equate to False
		'		r.time = time '
		'	) OR ( '
		# 
		# for conditions these handle bound records
		# 
		# - any overlapping records
		'		CASE WHEN r.start <> False THEN r.start ELSE Null END < end '
		'		AND '
		'		CASE WHEN r.end <> False THEN r.end ELSE Null END >= start '
		'	) OR ( '
		# - a record that has a lower bound in the bound period and unbound upper
		'		r.end = False'
		'		AND '
		'		CASE WHEN r.start <> False THEN r.start ELSE Null END >= start '
		'		AND '
		'		CASE WHEN r.start <> False THEN r.start ELSE Null END < end '
		'	) OR ( '
		# - a record that has an upper bound in the bound period and unbound lower
		'		r.start = False '
		'		AND '
		'		CASE WHEN r.end <> False THEN r.end ELSE Null END > start '
		'		AND '
		'		CASE WHEN r.end <> False THEN r.end ELSE Null END <= end '
		'	) OR ( '
		# now handle lower bound
		'		end IS NULL '
		'		AND ( '
		# - existing bound period includes start
		'			CASE WHEN r.end <> False THEN r.end ELSE Null END > start '
		'			AND '
		'			CASE WHEN r.start <> False THEN r.start ELSE Null END <= start '
		# - existing lower bounded record at same time
		'		) OR ( '
		'			r.start = start '
		'			AND '
		'			r.end = False '
		'		) '
		'	) OR ( '
		# now hand upper bound 
		'		start IS NULL '
		'		AND ( '
		# - existing bound period includes end
		'			CASE WHEN r.end <> False THEN r.end ELSE Null END >= end '
		'			AND '
		'			CASE WHEN r.start <> False THEN r.start ELSE Null END < end '
		# - existing upper bounded record at same time
		'		) OR ( '
		'			r.end = end '
		'			AND '
		'			r.start = False '
		'		) '
		'	) OR ( '
		# now handle unbound
		'		start IS NULL '
		'		AND '
		'		end IS NULL '
		'		AND '
		'		r.end = False '
		'		AND '
		'		r.start = False '
		'	)) '
		' ) '
		' WITH '
		'	row_index, feature_name, item, feature, value, '
		'	COLLECT(DISTINCT({ '
		'		time: existing_time, '
		'		start: existing_start, '
		'		end: existing_end, '
		'		existing_value: toString(existing_value), '
		'		submitted_at: submitted_at, '
		'		user: user, '
		'		access: access '
		'	})) as conflicts '
		' RETURN { '
		'	row_index: row_index, '
		'	input_feature: feature_name, '
		'	UID: item.uid, '
		'	feature: feature.name, '
		'	format: feature.format, '
		'	category_list: feature.category_list, '
		'	value: value, '
		'	conflicts: conflicts '
		' } '
		' ORDER BY row_index, feature.name_lower '
		' LIMIT 50 '
	)

	upload_table = (
		# load in the csv
		' LOAD CSV WITH HEADERS FROM $filename as csvLine '
		' WITH '
		'	csvLine, '
		'	trim(csvLine.person) as person, '
		'	split(trim(toUpper(csvLine.uid)), ".")[0] as uid, '
		'	split(trim(toUpper(csvLine.uid)), ".")[1] as replicate, '
		# time from date and time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.date, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.date, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.time, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.time, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.time, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.time, " ", "") '
		'			ELSE '
		'				"12:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as time, '
		# start time from start date and start time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`start date`, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.`start date`, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`start time`, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.`start time`, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.`start time`, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.`start time`, " ", "") '
		'			ELSE '
		'				"00:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as start, '
		# end time from end date and end time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`end date`, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.`end date`, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`end time`, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.`end time`, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.`end time`, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.`end time`, " ", "") '
		'			ELSE '
		'				"24:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as end '		
		# And identify the fields and traits assessed
		' MATCH  '
		'	(field:Field { '
		'		uid: toInteger(split(uid, "_")[0]) '
		'	}), '
		'	(item: Item { '
		'		uid: '
		'			CASE '
		'				WHEN size(split(uid, "_")) = 1 '
		'					THEN toInteger(uid) '
		'				ELSE '
		'					toUpper(uid) '
		'				END '
		'	}) '
		' UNWIND $features as feature_name '
		'	MATCH '
		'		(:RecordType {'
		'			name_lower: '
		'				CASE WHEN time IS NOT NULL THEN "trait" ELSE "condition" END'
		'		}) '
		'		<-[:OF_TYPE]-(feature: Feature { '
		'			name_lower: toLower(feature_name) '
		'		})-[:AT_LEVEL]->(item_level:ItemLevel { '
		'			name_lower: '
		'				CASE '
		'					WHEN split(uid, "_")[1] IS NULL '
		'						THEN "field" '
		'					WHEN toUpper(left(split(uid, "_")[1],1)) = "B" '
		'						THEN "block" '
		'					WHEN toUpper(left(split(uid, "_")[1],1)) = "T" '
		'						THEN "tree" '
		'					WHEN toUpper(left(split(uid, "_")[1],1)) = "S" '
		'						THEN "sample" '
		'					END '
		'		}) '
		# Check for data in table
		# all load_csv values are string so can just check size after trimming whitespace  
		'	WHERE size(csvLine[feature_name]) > 0 '
		'	WITH '
		'		field, item, feature, item_level.name_lower as level, '
		'		person, time, start, end, replicate, '
		'		csvLine[feature_name] as value, '
		# these are unique to table uploads, also probably not necessary 
		# but allows differentiation of defaulted time from set time
		' 		csvLine.time as text_time, '
		'		csvLine.date as text_date, '
		'		csvLine.`start date` as text_start_date, '
		'		csvLine.`start time` as text_start_time, '
		'		csvLine.`end date` as text_end_date, '
		'		csvLine.`end time` as text_end_time, '
		# the following are null where FB has values to allow shared code between formats
		'		null as timestamp, '
		'		null as location '
		# for trait data if no time is set then drop the row 
		# for condition data we allow null time but need to check is this type 
		# by looking for one of the relevant fields e.g. `start date`
		' 		WHERE (time IS NOT Null) OR (csvLine.`start date` IS NOT NULL) '
		+ shared_upload_code
	)

	get_fields_treecount = (
		' MATCH (country:Country)<-[:IS_IN]-(region: Region) '
		' OPTIONAL MATCH (region)<-[:IS_IN]-(farm: Farm) '
		' OPTIONAL MATCH (farm)<-[:IS_IN]-(field: Field) '
		' OPTIONAL MATCH '
		'	(field)'
		'	<-[:IS_IN]-(:FieldTrees)'
		'	<-[:FOR]-(field_tree_counter:Counter {name:"tree"}) '
		' OPTIONAL MATCH '
		'	(field)'
		'	<-[:IS_IN*2]-(block:Block)'
		'	<-[:IS_IN]-(:BlockTrees)'
		'	<-[:FOR]-(block_tree_counter:Counter {name:"tree"}) '
		' WITH '
		'	country, '
		'	region, '
		'	farm, '
		'	field, '
		'	field_tree_counter.count as field_trees, '
		'	{'
		'		name: block.name, '
		'		label:"Block", '
		'		treecount: block_tree_counter.count '
		'	} as blocks, '
		'	block_tree_counter.count as block_trees '
		' WITH '
		'	country, '
		'	region, '
		'	farm, '
		'	{ '
		'		name: field.name, '
		'		label:"Field", '
		'		treecount: field_trees - sum(block_trees), '
		'		children: FILTER(block IN collect(blocks) WHERE block["name"] IS NOT NULL)'
		'	} as fields '
		' WITH '
		'	country, '
		'	region, '
		'	{'
		'		name: farm.name, '
		'		label: "Farm", '
		'		children: FILTER(field IN collect(fields) WHERE field["name"] IS NOT NULL)'
		'	} as farms '
		' WITH '
		'	country, '
		'	{'
		'		name: region.name, '
		'		label:"Region", '
		'		children: FILTER(farm IN collect(farms) WHERE farm["name"] IS NOT NULL)'
		'	} as regions '
		' WITH '
		'	{'
		'		name: country.name, '
		'		label:"Country", '
		'		children: FILTER(region IN collect (regions) WHERE region["name"] IS NOT NULL)'
		'	} as countries '
		' RETURN countries '
	)
	get_submissions_range = (
		# first get all the data collections and link to a base node formed from block/field/farm
		' MATCH '
		'	(:User {username_lower: toLower($username)}) '
		'		-[:SUBMITTED*4]->() '
		'		-[s:SUBMITTED]->(data: Data) '
		'		-[:DATA_FOR]->(dit) '
		'		-[:FOR_TRAIT*..2]->(trait: Trait), '
		'	(dit) '
		'		-[:FOR_ITEM]->(item) '
		' WHERE s.time >=$starttime AND s.time <= $endtime'
		' OPTIONAL MATCH '
		'	(item)-[:FROM_TREE*2]->(tree_item_tree:Tree) '
		' OPTIONAL MATCH '
		'	(tree_item_tree)-[:IS_IN {current: True}]-() '
		'	-[:IS_IN]->(tree_item_block: Block) '
		'	-[:IS_IN*2]->(tree_item_block_field: Field) '
		' OPTIONAL MATCH '
		'	(tree_item_tree)-[:IS_IN*2]->(tree_item_field: Field) '
		' OPTIONAL MATCH '
		'	(item) '
		'	-[:IS_IN {current: True}]-()'
		'	-[:IS_IN]->(tree_block: Block) '
		'	-[:IS_IN*2]->(tree_block_field: Field) '
		' OPTIONAL MATCH '
		'	(item) '
		'	-[:IS_IN*2]->(tree_field) '
		' OPTIONAL MATCH '
		'	(item) '
		'	-[:IS_IN*2]->(block_field: Field) '
		' OPTIONAL MATCH '
		'	(item) '
		'	-[:IS_IN]->(field_farm:Farm) '
		' RETURN '
		'	"Trait" as d_label, '
		'	trait.name + " (" + count(distinct(data)) + ")" as d_name, '
		'	COALESCE( '
		'		id(tree_item_block), '
		'		id(tree_item_field), '
		'		id(tree_block), '
		'		id(tree_field), '
		'		id(block_field), '
		'		id(field_farm) '
		'		) + "_" + id(trait) as d_id, '
		'	filter(i IN labels(item) WHERE i <> "Item")[0] as n_label, '
		'	CASE WHEN '
		'		trait.level in ["sample", "leaf", "branch", "tree"] '
		'		THEN '
		'			count(DISTINCT item) '
		'		ELSE '
		'			item.name '
		'		END '	
		'	 	as n_name,'
		'	CASE WHEN '
		'		trait.level in ["sample", "leaf", "branch", "tree"] '
		'		THEN '
		'			COALESCE( '
		'				id(tree_item_block), '
		'				id(tree_item_field), '
		'				id(tree_block), '
		'				id(tree_field) '
		'				) + "_" + id(trait) + filter(i IN labels(item) WHERE i <> "Item")[0] + "_count_node" '
		'		ELSE '
		'			id(item) '
		'		END '
		'		as n_id, '
		'	"FROM" as r_type, '
		'	COALESCE( '
		'		id(tree_item_block), '
		'		id(tree_item_field), '
		'		id(tree_block), '
		'		id(tree_field), '
		'		id(block_field), '
		'		id(field_farm) '
		'		) + "_" + id(trait) + filter(i IN labels(item) WHERE i <> "Item")[0] + "_data_node" as r_id, '
		'	COALESCE( '
		'		id(tree_item_block), '
		'		id(tree_item_field), '
		'		id(tree_block), '
		'		id(tree_field), '
		'		id(block_field), '
		'		id(field_farm) '
		'		) + "_" + id(trait) as r_start, '
		'	CASE WHEN '
		'		trait.level in ["sample", "leaf", "branch", "tree"] '
		'		THEN '
		'			COALESCE( '
		'				id(tree_item_block), '
		'				id(tree_item_field), '
		'				id(tree_block), '
		'				id(tree_field) '
		'				) + "_" + id(trait) + filter(i IN labels(item) WHERE i <> "Item")[0] + "_count_node" '
		'		ELSE '
		'			id(item) '
		'		END '
		'		as r_end '
		' UNION '
		# link the above into block context where relevant
		' MATCH (:User {username_lower: toLower($username)}) '
		'	-[:SUBMITTED*4]->() '
		'	-[s:SUBMITTED]->(:Data) '
		'	-[:DATA_FOR]->() '
		'	-[:FOR_ITEM]->(item:Item) '
		' WHERE s.time >= $starttime AND s.time <= $endtime'
		' WITH item '
		' OPTIONAL MATCH (item) '
		'	-[:FROM_TREE*2]->(:Tree) '
		'	-[:IS_IN {current: True}]->(:BlockTrees) '
		'	-[:IS_IN]->(tree_item_block:Block)'
		' OPTIONAL MATCH (item) '
		'	-[:IS_IN {current: True}]->(:BlockTrees) '
		'	-[:IS_IN]->(tree_block:Block) '
		' WITH distinct(COALESCE(tree_item_block, tree_block)) as block '
		' MATCH (block)-[:IS_IN*2]->(field:Field) '
		' RETURN '
			' "Block" as d_label, '
			' block.name as d_name, '
			' id(block) as d_id, '
			' "Field" as n_label, '
			' field.name as n_name, '
			' id(field) as n_id, '
			' "IS_IN" as r_type,  '
			' (id(block) + "_" + id(field)) as r_id, '
			' id(block) as r_start, '
			' id(field) as r_end'
		' UNION '
		# and then blocks into fields
		' MATCH (:User {username_lower: toLower($username)}) '
		'	-[:SUBMITTED*4]->() '
		'	-[s:SUBMITTED]->(:Data) '
		'	-[:DATA_FOR]->() '
		'	-[:FOR_ITEM]->(item:Item) '
		' WHERE s.time >=$starttime AND s.time <= $endtime'
		' WITH item '
		' OPTIONAL MATCH (item) '
		'	-[:FROM_TREE*2]->(:Tree) '
		'	-[:IS_IN*2]->(tree_item_block: Block)'
		' OPTIONAL MATCH (item) '
		'	-[:IS_IN*2]->(tree_block: Block) '
		' WITH distinct(COALESCE('
		'	tree_item_block, '
		'	tree_block, '
		'	CASE WHEN "Block" in labels(item) THEN item END '
		'	)) as block '
		' WHERE block IS NOT NULL'
		' MATCH (block)-[:IS_IN*2]->(field:Field) '
		' RETURN '
		' "Block" as d_label, '
		' block.name as d_name, '
		' id(block) as d_id, '
		' "Field" as n_label, '
		' field.name as n_name, '
		' id(field) as n_id, '
		' "IS_IN" as r_type,  '
		' (id(block) + "_" + id(field)) as r_id, '
		' id(block) as r_start, '
		' id(field) as r_end'
		' UNION '
		# and then fields into farms
		' MATCH (:User {username_lower: toLower($username)}) '
		'	-[:SUBMITTED*4]->() '
		'	-[s:SUBMITTED]->(:Data) '
		'	-[:DATA_FOR]->() '
		'	-[:FOR_ITEM]->(item:Item) '
		' WHERE s.time >=$starttime AND s.time <= $endtime'
		' WITH item '
		' OPTIONAL MATCH (item) '
		'	-[:FROM_TREE*2]->(:Tree) '
		'	-[:IS_IN*2]->(tree_item_field: Field)'
		' OPTIONAL MATCH (item) '
		'	-[:IS_IN*2]->(field_item_field: Field) '
		' WITH distinct(COALESCE(tree_item_field, field_item_field, item)) as field '
		' MATCH (field)-[:IS_IN]->(farm:Farm) '
		' RETURN '
		' "Field" as d_label, '
		' field.name as d_name, '
		' id(field) as d_id, '
		' "Farm" as n_label, '
		' farm.name as n_name, '
		' id(farm) as n_id, '
		' "IS_IN" as r_type,  '
		' (id(field) + "_" + id(farm)) as r_id, '
		' id(field) as r_start, '
		' id(farm) as r_end'
		' UNION '
		# and then farms into regions
		' MATCH (:User {username_lower: toLower($username)}) '
		'	-[:SUBMITTED*4]->() '
		'	-[s:SUBMITTED]->(:Data) '
		'	-[:DATA_FOR]->() '
		'	-[:FOR_ITEM]->(item:Item) '
		' WHERE s.time >=$starttime AND s.time <= $endtime'
		' WITH item '
		' OPTIONAL MATCH (item) '
		'	-[:FROM_TREE*2]->(:Tree) '
		'	-[:IS_IN*2]->(tree_item_field: Field)'
		' OPTIONAL MATCH (item) '
		'	-[:IS_IN*2]->(field_item_field: Field) '
		' WITH distinct(COALESCE(tree_item_field, field_item_field, item)) as field '
		' MATCH '
		'	(field)-[:IS_IN]->(farm:Farm) '
		'	-[:IS_IN]->(region:Region) '
		' RETURN '
		' "Farm" as d_label, '
		' farm.name as d_name, '
		' id(farm) as d_id, '
		' "Region" as n_label, '
		' region.name as n_name, '
		' id(region) as n_id, '
		' "IS_IN" as r_type,  '
		' (id(farm) + "_" + id(region)) as r_id, '
		' id(farm) as r_start, '
		' id(region) as r_end '
		' UNION '
		# and then regions into countries
		' MATCH (:User {username_lower: toLower($username)}) '
		'	-[:SUBMITTED*4]->() '
		'	-[s:SUBMITTED]->(:Data) '
		'	-[:DATA_FOR]->() '
		'	-[:FOR_ITEM]->(item:Item) '
		' WHERE s.time >=$starttime AND s.time <= $endtime'
		' WITH item '
		' OPTIONAL MATCH (item) '
		'	-[:FROM_TREE*2]->(:Tree) '
		'	-[:IS_IN*2]->(tree_item_field: Field)'
		' OPTIONAL MATCH (item) '
		'	-[:IS_IN*2]->(field_item_field: Field) '
		' WITH distinct(COALESCE(tree_item_field, field_item_field, item)) as field '
		' MATCH '
		'	(field)-[:IS_IN]->(:Farm) '
		'	-[:IS_IN]->(region:Region) '
		'	-[:IS_IN]->(country:Country) '
		' RETURN '
		' "Region" as d_label, '
		' region.name as d_name, '
		' id(region) as d_id, '
		' "Country" as n_label, '
		' country.name as n_name, '
		' id(country) as n_id, '
		' "IS_IN" as r_type,  '
		' (id(region) + "_" + id(country)) as r_id, '
		' id(region) as r_start, '
		' id(country) as r_end '
	)
