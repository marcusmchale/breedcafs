class Cypher:
	def __init__(self):
		pass
	# user procedures
	allowed_emails = (
		' MATCH '
		'	(e: Emails) '
		' RETURN '
		'	e.allowed '
	)
	user_allowed_emails = (
		' MATCH '
		'	(u:User) '
		' WITH '
		'	COLLECT (DISTINCT u.email) as registered_emails '
		' MATCH '
		'	(user:User {'
		'		username_lower : toLower(trim($username)) '
		'	}) '
		'	-[: SUBMITTED]->(: Submissions) '
		'	-[: SUBMITTED]->(e: Emails) '
		' RETURN '
		'	FILTER (n in e.allowed WHERE NOT n in registered_emails) as user_allowed '
	)
	email_find = (
		' MATCH '
		'	(user: User { '
		'		email: toLower(trim($email)) '
		'	}) '
		' RETURN '
		'	user '
	)
	confirm_email = (
		' MATCH '
		'	(user: User { '
		'		email: toLower(trim($email)) '
		'	}) '
		' SET '
		'	user.confirmed = true '
	)
	user_find = (
		' MATCH '
		'	(user: User) '
		'		WHERE '
		'			user.username_lower = toLower($username) '
		'		OR '
		'			user.email = toLower(trim($email)) '
		' RETURN '
		'	user '
	)
	username_find = (
		' MATCH '
		'	(user: User { '
		'		username_lower: toLower($username)'
		'	}) '
		' RETURN '
		'	user '
	)
	user_affiliations = (
		' MATCH '
		'	(u: User { '
		'		username_lower: toLower($username) '
		'	}) '
		'	-[a: AFFILIATED]->(p: Partner) '
		' OPTIONAL MATCH '
		'	(p)<-[: AFFILIATED {admin: true}]-(admin: User) '
		' RETURN '
		'	p.name , '
		'	p.fullname , '
		'	a.confirmed as confirmed, '
		'	a.data_shared as data_shared , '
		'	admin.email as admin_email'
	)
	add_affiliations = (
		' UNWIND '
		'	$partners as partner '
		' 	MATCH '
		'		(u:User { '
		'			username_lower: toLower(trim($username)) '
		'		}), '
		'		(p:Partner { '
		'			name_lower: toLower(trim(partner)) '
		'		}) '
		' 	MERGE '
		'		(u)-[a: AFFILIATED { '
		'			data_shared: false, '
		'			admin: false, '
		'			confirm_timestamp: [], '
		'			confirmed: false '
		' 		}]->(p) '
		' 	ON CREATE SET '
		'		a.add_timestamp = timestamp() '
		' 	RETURN '
		'		p.name '
	)
	remove_affiliations = (
		' UNWIND '
		'	$partners as partner '
		' 	MATCH '
		'		(u:User { '
		'			username_lower: toLower(trim($username)) '
		'		 }) '
		'		-[a:AFFILIATED { '
		'			data_shared: false '
		'		}]->(p: Partner {'
		'			name_lower: toLower(trim(partner)) '
		'		}) '
		' 	WHERE '
		'		size(a.confirm_timestamp) = 0 '
		' 	DELETE '
		'		a '
		' 	RETURN p.name '
	)
	password_reset = (
		' MATCH '
		'	(user: User { '
		'		email : toLower(trim($email)) '
		' 	}) '
		' SET user.password = $password '
	)
	user_register = (
		# This is a little cautious using merge to prevent overwriting a user profile if it is called in error
		' MATCH '
		'	(partner:Partner {'
		'		name_lower: toLower(trim($partner)) '
		'	}) '
		' MERGE '
		'	(user:User { '
		'		username_lower: toLower(trim($username)) '
		'	}) '
		'	ON CREATE SET '
		'		user.username = trim($username), '
		'		user.password = $password, ' 
		'		user.email = toLower(trim($email)), '
		'		user.name = $name, '
		'		user.time = timestamp(), '
		'		user.access = ["user"], '
		'		user.confirmed = false, '
		'		user.found = false '
		'	ON MATCH SET '
		'		user.found = TRUE '
		' WITH '
		'	user, partner '	
		' WHERE '
		'	user.found = false '
		' CREATE '
		'	(user)-[r: AFFILIATED { '
		'		data_shared: true, '
		'		confirmed: false, '
		'		confirm_timestamp: [], '
		'		admin: false '				
		'	}]->(partner), '
		'	(user)-[: SUBMITTED]->(sub: Submissions), '
		'		(sub)-[: SUBMITTED]->(: Emails {allowed :[]}),'
		'		(sub)-[: SUBMITTED]->(locations: Locations), '
		'			(locations)-[: SUBMITTED]->(: Countries), '
		'			(locations)-[: SUBMITTED]->(: Regions), '
		'			(locations)-[: SUBMITTED]->(: Farms), '
		'		(sub)-[:SUBMITTED]->(items: Items), '
		'			(items)-[: SUBMITTED]->(: Fields), '
		'			(items)-[: SUBMITTED]->(: Blocks), '
		'			(items)-[: SUBMITTED]->(: Trees), '
		'			(items)-[: SUBMITTED]->(: Samples), '
		'		(sub)-[:SUBMITTED]->(: Records) '
	)
	add_allowed_email = (
		' MATCH '
		'	(all: Emails) '
		' WITH '
		'	all.allowed as allowed_emails '
		' UNWIND '
		'	allowed_emails as email '
		' WITH '
		'	COLLECT(DISTINCT email) as set '
		' WHERE '
		'	NOT toLower(trim($email)) IN set '
		' MATCH '
		'	(:User { '
		'		username_lower: toLower(trim($username)) '
		' 	}) '
		'	-[:SUBMITTED]->(: Submissions) '
		'	-[:SUBMITTED]->(e: Emails) '
		' SET e.allowed = e.allowed + [toLower(trim($email))] '
		' RETURN toLower(trim($email)) '
	)
	remove_allowed_email = (
		' MATCH '
		'	(:User { '
		'		username_lower: toLower(trim($username)) '
		' 	}) '
		'	-[:SUBMITTED]->(: Submissions) '
		'	-[:SUBMITTED]->(e: Emails) '
		' WITH e, extract(x in $email | toLower(trim(x))) as emails'
		' SET e.allowed = FILTER (n in e.allowed WHERE NOT n IN emails) '
		' RETURN emails '
	)
	user_del = (
		' MATCH '
		'	(u:User { '
		'		email: toLower(trim($email)), '
		'		confirmed: false '
		'	}) '
		' OPTIONAL MATCH '
		'	(u)-[:SUBMITTED*..3]->(n) '
		' DETACH DELETE '
		' u,n '
	)
	partner_admin_users = (
		' MATCH '
		'	(:User { '
		'		username_lower: toLower(trim($username)) '
		' 	}) '
		'	-[: AFFILIATED { '
		'		admin: true '
		'	}]->(p:Partner) '
		' WITH p '
		' MATCH '
		'	(p)<-[a:AFFILIATED]-(u:User) ' 
		' RETURN { '
		'	Username: u.username, '
		'	Email: u.email, '
		'	Name: u.name, '
		'	Partner: p.name, '
		'	PartnerFullName: p.fullname, '
		'	Confirmed: a.confirmed '
		' } '
	)
	global_admin_users = (
		' MATCH '
		'	(u:User)-[a:AFFILIATED]->(p:Partner) '
		' RETURN { '
		'	Username : u.username, '
		'	Email : u.email, '
		'	Name : u.name, '
		'	Partner : p.name, '
		'	PartnerFullName : p.fullname, '
		'	Confirmed : a.confirmed '
		' } '
	)
	# these functions toggle the confirmed status so do both confirm/un-confirm operations
	partner_confirm_users = (
		' MATCH '
		'	(user:User { '
		'		username_lower: toLower(trim($username)) '
		' 	}) '
		'	-[:AFFILIATED {admin : true}]->(p:Partner) '
		' WHERE '
		'	"partner_admin" in user.access'
		' MATCH '
		'	(p)<-[a:AFFILIATED]-(u:User) '
		' UNWIND '
		'	$confirm_list as confirm '
		' 	WITH '
		'		p,a,u '
		' 	WHERE '
		'		p.name_lower = toLower(trim(confirm["partner"])) '
		' 	AND '
		'		u.username_lower = toLower(trim(confirm["username"])) '
		' 	SET '
		'		a.confirmed = NOT a.confirmed, '
		'		a.confirm_timestamp = a.confirm_timestamp + timestamp() '
		' 	RETURN u.name '
	)
	global_confirm_users = ( 
		' MATCH '
		'	(p:Partner)<-[a:AFFILIATED]-(u:User) '
		' UNWIND '
		'	$confirm_list as confirm '
		' WITH '
		'	p,a,u '
		' WHERE '
		'	p.name_lower = toLower(trim(confirm["partner"])) '
		' AND '
		'	u.username_lower = toLower(trim(confirm["username"])) '
		' SET '
		'	a.confirmed = NOT a.confirmed, '
		'	a.confirm_timestamp = a.confirm_timestamp + timestamp() '
		' RETURN u.name '
	)
	partner_admins = (
		' MATCH '
		'	(u:User)-[a:AFFILIATED]->(p:Partner) '
		' RETURN { '
		'	Username : u.username, '
		'	Email : u.email, '
		'	Name : u.name, '
		'	Partner : p.name, '
		'	PartnerFullName : p.fullname, '
		'	Confirmed : a.admin '
		' } '
	)
	confirm_admins = (
		' MATCH '
		'		(p:Partner)<-[a:AFFILIATED]-(u:User) '
		' UNWIND $admins as admin '
		' 	WITH '
		'		p,a,u '
		' 	WHERE '
		'		p.name_lower = toLower(trim(admin["partner"])) '
		' 	AND '
		'		u.username_lower = toLower(trim(admin["username"])) '
		' 	SET '
		'		a.admin = NOT a.admin '
		'	WITH u '
		'		MATCH (u)-[a:AFFILIATED]->(:Partner) '
		'		WITH u, collect(a.admin) as admin_rights '
		'		set u.access = CASE '
		'			WHEN true IN admin_rights '
		'			THEN ["user","partner_admin"] '
		'			ELSE ["user"] '
		'			END '
		' 	RETURN '
		'		u.name '
	)

	# Upload procedures
	upload_check_value = (
		# make sure that all the entries match accepted entries
		# handles empty items and white space
		# forces strings to lower case and float/integer types
		# removes % symbols
		# ! ensure to declare feature (as node) and value (from file) before including
		' CASE '
		'	WHEN feature.format = "multicat" '
		'		THEN CASE '
		'			WHEN size(FILTER (n in split(value, ":") WHERE size(n) > 0)) '
		'				= size(FILTER (n in split(value, ":") WHERE toLower(trim(n)) in '
		'					EXTRACT(item in feature.category_list | toLower(item)))) '
		'			THEN trim(value) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "categorical" '
		'		THEN [category IN feature.category_list WHERE  toLower(category) = toLower(trim(value)) | category][0] '
		'	WHEN feature.format = "text" '
		'		THEN CASE '
		'			WHEN feature.name_lower = "assign to trees" '
		'				THEN CASE '
		'					WHEN size(split(value, "," )) = size(filter(x in split(value, ",") where toInteger(trim(x)) IS NOT NULL)) '
		'					THEN value '
		'					ELSE Null '
		'					END '
		'			WHEN feature.name_lower = "assign to block" '
		'				THEN toInteger(value) '
		'			WHEN feature.name contains "time" '
		'				THEN CASE '
		'					WHEN size(split(value, ":")) = 2 '
		'					AND size(split(value, ":")[0]) <= 2 '
		'					AND toInteger(trim(split(value, ":")[0])) <=24 '
		'					AND toInteger(trim(split(value, ":")[0])) >= 0 '
		'					AND size(split(value, ":")[1]) <= 2 '
		'					AND toInteger(trim(split(value, ":")[1])) < 60 '
		'					AND toInteger(trim(split(value, ":")[1])) >= 0 '
		'						THEN trim(value) '
		'					ELSE Null '
		'					END '
		'			ELSE '
		'				toString(value) '
		'			END '
		'	WHEN feature.format = "percent" '
		'		THEN CASE '
		'			WHEN toFloat(replace(value, "%", "")) IS NOT NULL '
		'				THEN toFloat(replace(value, "%", "")) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "counter" '
		'		THEN CASE '
		'			WHEN toInteger(value) IS NOT NULL '
		'				THEN toInteger(value) '
		'			ELSE '
		'				Null '
		'			END '
		'	WHEN feature.format = "numeric" '
		'		THEN CASE '
		'			WHEN toFloat(value) IS NOT NULL '
		'				THEN toFloat(value) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "boolean" '
		'		THEN CASE '
		'			WHEN toLower(value) in ["yes","y"] '
		'				THEN True '
		'			WHEN toLower(value) in ["no","n"] '
		'				THEN False '
		'			WHEN toBoolean(value) IS NOT NULL '
		'				THEN toBoolean(value) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "location" '
		'		THEN CASE '
		'			WHEN size(split(value, ";")) = 2 '
		'			AND toFloat(trim(split(value, ";")[0])) IS NOT NULL '
		'			AND toFloat(trim(split(value, ";")[1])) IS NOT NULL '
		'				THEN trim(value) '
		'			ELSE Null '
		'			END '
		'	WHEN feature.format = "date" '
		'		THEN CASE '
		'			WHEN size(split(value, "-")) = 3 '
		'			AND size(trim(split(value, "-")[0])) = 4 '
		'			AND size(trim(split(value, "-")[1])) <= 2 '
		'			AND size(trim(split(value, "-")[1])) >= 1 '
		'			AND toInteger(trim(split(value, "-")[1])) >= 1 '
		'			AND toInteger(trim(split(value, "-")[1])) <= 12 '
		'			AND size(trim(split(value, "-")[2])) <= 2 '
		'			AND size(trim(split(value, "-")[2])) >= 1 '
		'			AND toInteger(trim(split(value, "-")[1])) >= 1 '
		'			AND toInteger(trim(split(value, "-")[1])) <= 31 '
		'			THEN '
		'				trim(value) '
		'			ELSE '
		'				Null '
		'			END '
		'	ELSE Null '
		'	END '
	)

	#shared_upload_code = (
	#	' FOREACH (n in CASE '
	#	'	WHEN level = "field" '
	#	'		THEN [1] ELSE [] END | '
	#	'			MERGE '
	#	'				(item)<-[: FOR_ITEM]-(:ItemFeature)-[: FOR_FEATURE]->(feature) '
	#	' ) '
	#	' FOREACH (n in CASE '
	#	'	WHEN level in ["block", "tree", "sample"] '
	#	'		THEN [1] ELSE [] END | '
	#	'			MERGE '
	#	'				(field)<-[: FROM_FIELD]-(field_feature: FieldFeature)-[: FOR_FEATURE]->(feature) '
	#	'			MERGE '
	#	'				(item)<-[: FOR_ITEM]-(:ItemFeature)-[: FOR_FEATURE]->(field_feature) '
	#	' ) '
	#	# get rid of some of the optional matches since they are no longer needed
	#	' WITH '
	#	'	record_type, '
	#	'	field, item, feature, level, time, start, end, replicate, '
	#	'	person, '
	#	'	location, timestamp, text_time, text_date, text_start_time, text_start_date, text_end_time, text_end_date, '
	#	+ upload_check_value +
	#	' AS value WHERE value IS NOT NULL '
	#	# get the user submission tracking nodes
	#	' MATCH '
	#	'	(:User { '
	#	'		username_lower : toLower(trim($username))'
	#	'	}) '
	#	'	-[: SUBMITTED]->(: Submissions) '
	#	'	-[: SUBMITTED]->(data_sub: Records) '
	#	# and the item/feature node
	#	' MATCH '
	#	' (item)<-[: FOR_ITEM]-(item_feature: ItemFeature)-[ :FOR_FEATURE*..2]->(feature) '
	#	' OPTIONAL MATCH '
	#	' (field_feature: FieldFeature)<-[: FOR_FEATURE]-(item_feature) '
	#	# Perform optional matches so can modify relationships for some features
	#	# In case feature "assign to block"
	#	# if has block assignment find current IS_IN block-trees rel (to remove current flag) and counter (to decrement)
	#	' OPTIONAL MATCH '
	#	'	(item) '
	#	'	-[is_in_block_current:IS_IN]->(: BlockTrees) '
	#	# and find the block by uid for update of IS_IN block-trees
	#	' OPTIONAL MATCH '
	#	'	(block_update: Block {id: value}) '
	#	'	-[: IS_IN]->(: FieldBlocks)'
	#	'	-[: IS_IN]->(field) '
	#	' OPTIONAL MATCH '
	#	'	(block_update) '
	#	'	<-[: IS_IN]-(: BlockTrees) '
	#	'	<-[: FOR]-(block_update_counter: Counter) '
	#	# Using many with statements around long optional match blocks
	#	# otherwise there is a database error I haven't diagnosed
	#	' WITH '
	#	'	record_type, '
	#	'	field, item, feature, level, item_feature, coalesce(field_feature, item_feature) as field_feature, '
	#	'	time, start, end, '
	#	'	location, timestamp, text_time, text_date, text_start_time, text_start_date, text_end_time, text_end_date, '
	#	'	replicate, value, person, '
	#	'	data_sub, '
	#	'	is_in_block_current, block_update '
	#	# In case sample feature "assign to trees"
	#	# should only work for samples currently registered to a field and not a tree
	#	# find current assignment
	#	' OPTIONAL MATCH '
	#	'	(item)-[from_current: FROM]->(:ItemSamples)-[:FROM]->(field) '
	#	# and update tree by uid
	#	' OPTIONAL MATCH '
	#	'	(tree_update: Tree)-[: IS_IN*2]->(field) '
	#	'	WHERE tree_update.id in extract(x in split(toString(value), ",") | toInteger(trim(x))) '
	#	# Sample source if sourced from another sample
	#	' OPTIONAL MATCH '
	#	'	(item)-[: FROM]->(source_sample: Sample)-[:FROM]->(:ItemSamples) '
	#	' WITH '
	#	'	record_type, '
	#	'	field, item, feature, level, item_feature, field_feature, '
	#	'	time, start, end, '
	#	'	location, timestamp, text_time, text_date, text_start_time, text_start_date, text_end_time, text_end_date, '
	#	'	replicate, value, person, '
	#	'	data_sub, '
	#	'	is_in_block_current, block_update, '
	#	'	from_current, '
	#	'	collect(tree_update) as tree_update, '
	#	'	source_sample '
	#	# variety matching
	#	' OPTIONAL MATCH '
	#	'	(: Variety)'
	#	'	<-[:OF_VARIETY]-(: FieldVariety) '
	#	'	<-[of_variety_current:OF_VARIETY]-(item) '
	#	' OPTIONAL MATCH '
	#	'	(variety_update: Variety) '
	#	'	WHERE '
	#	'		toLower(variety_update.name_lower) = toLower(toString(value)) '
	#	'	OR ('
	#	'		variety_update.code IS NOT NULL '
	#	'		AND '
	#	'		toLower(variety_update.code) = toLower(toString(value)) '
	#	'	) '
	#	# need to check for conflicts with existing records before merger due to condition flexible start/end
	#	' MERGE '
	#	'	(r:Record { '
	#	'		time : CASE WHEN time IS NULL THEN False ELSE time END, '
	#	'		start: CASE WHEN start IS NULL THEN False ELSE start END, '
	#	'		end: CASE WHEN end IS NULL THEN False ELSE end END, '
	#	'		replicate: CASE WHEN replicate IS NULL THEN 1 ELSE replicate END '
	#	'	}) '
	#	'	-[:RECORD_FOR]->(item_feature) '
	#	'	ON MATCH SET '
	#	'		r.found = True '
	#	'	ON CREATE SET '
	#	'		r.found = False, '
	#	'		r.location = location, '
	#	'		r.person = person, '
	#	'		r.timestamp = timestamp, '
	#	'		r.text_date = text_date, '
	#	'		r.text_time = text_time, '
	#	'		r.text_start_date = text_start_date, '
	#	'		r.text_start_time = text_start_time, '
	#	'		r.text_start_date = text_end_date, '
	#	'		r.text_start_time = text_end_time, '
	#	'		r.value = CASE '
	#	' 			WHEN feature.format <> "multicat" THEN value '
	#	'			ELSE extract(i in FILTER (n in split(value, ":") WHERE  size(n) > 0 )| toLower(trim(i)))'
	#	'			END '
	#	# additional statements to occur when new data point
	#	' FOREACH (n IN CASE '
	#	'		WHEN r.found = False '
	#	'			THEN [1] ELSE [] END | '
	#	# track user submissions through /User/FieldFeature container
	#	'				MERGE '
	#	'					(data_sub)'
	#	'					-[:SUBMITTED]->(uff:UserFieldFeature) '
	#	'					-[:CONTRIBUTED]->(field_feature) '
	#	# then finally the data with a timestamp
	#	'				MERGE '
	#	'					(uff)-[s1:SUBMITTED]->(r) '
	#	'					ON CREATE SET '
	#	'						s1.time = timestamp() '
	#	' ) '
	#	# Now update relationship feature values
	#	# "assign to block"
	#	# only allow when not already assigned to block
	#	' FOREACH (n IN CASE '
	#	'	WHEN r.value = value '
	#	'	AND feature.name_lower = "assign to block" '
	#	'	AND is_in_block_current IS NULL '
	#	'	AND block_update IS NOT NULL '
	#	'	THEN [1] ELSE [] END | '
	#	'		CREATE (t:Test)'
	#	'		MERGE '
	#	'			(block_trees_update: BlockTrees)-[:IS_IN]-> '
	#	'			(block_update) '
	#	'		MERGE '
	#	'			(block_tree_counter_update: Counter { '
	#	'				name: "tree", '
	#	'				uid: (block_update.uid + "_tree") '
	#	'			})-[:FOR]->(block_trees_update) '
	#	'			ON CREATE SET '
	#	'			block_tree_counter_update.count = 0 '
	#	'		SET block_tree_counter_update._LOCK_ = True '
	#	'		MERGE '
	#	'			(item)-[s1:IS_IN]->(block_trees_update) '
	#	'		ON CREATE SET '
	#	'			s1.time = timestamp(), '
	#	'			s1.user = $username '
	#	'		SET '
	#	'			block_tree_counter_update.count = block_tree_counter_update.count + 1 '
	#	'		REMOVE '
	#	'			block_tree_counter_update._LOCK_ '
	#	' ) '
	#	# "assign to trees"
	#	# In this case samples are either:
	#	#   - registered to a field where the relationship is preserved through the UID
	#	#      - can't update from a tree '
	#	#      - the submitting user and time is stored in the user_samples relationship
	#	#   - registered to trees adjusted through record submission, also recorded.
	#	# so we can safely delete this relationship and just create the new one.
	#	' FOREACH (n IN CASE '
	#	'	WHEN r.value = value '
	#	'	AND feature.name_lower = "assign to trees" '
	#	'	AND from_current IS NOT NULL '
	#	'	AND tree_update IS NOT NULL '
	#	# only allow setting source tree property on primary source sample
	#	'	AND source_sample IS NULL '
	#	'	THEN [1] ELSE [] END | '
	#	'		DELETE from_current '
	#	'		FOREACH (sampled_tree IN tree_update | '
	#	'			MERGE '
	#	'				(item_samples: ItemSamples)-[: FROM]->(sampled_tree) '
	#	'			MERGE '
	#	'				(item)-[s1: FROM]->(item_samples) '
	#	'			ON CREATE SET '
	#	'				s1.time = timestamp(), '
	#	'				s1.user = $username '
	#	'		) '
	#	' ) '
	#	# update variety rels
	#	' FOREACH (n IN CASE '
	#	'	WHEN r.value = value '
	#	'	AND feature.name_lower contains "variety" '
	#	'	AND variety_update IS NOT NULL '
	#	# only allow setting variety properties on primary source sample
	#	'	AND source_sample IS NULL '
	#	'	THEN [1] ELSE [] END | '
	#	'		DELETE of_variety_current '
	#	'		MERGE '
	#	'			(field)'
	#	'			-[: CONTAINS_VARIETY]->(fv: FieldVariety) '
	#	'			-[: OF_VARIETY]->(variety_update) '
	#	'		MERGE '
	#	'			(item)-[s1: OF_VARIETY]->(fv) '
	#	'		ON CREATE SET '
	#	'			s1.time = timestamp(), '
	#	'			s1.user = $username '
	#	' ) '
	#	# - sample harvest time (stored as sample.time)
	#	# Only allow setting harvest properties on primary source sample
	#	' FOREACH (n IN CASE '
	#	'	WHEN r.value = value '
	#	'	AND r.value IS NOT NULL '
	#	'	AND source_sample IS NULL '
	#	'	AND feature.name_lower = "harvest date" '
	#	'	AND item.`harvest date` IS NULL '
	#	'	THEN [1] ELSE [] END | '
	#	'		SET '
	#	'			item.`harvest date` = value, '
	#	'			item.time = CASE '
	#	'				WHEN item.`harvest time` IS NULL '
	#	'				THEN apoc.date.parse(value + " 12:00", "ms", "yyyy-MM-dd HH:mm") '
	#	'				ELSE apoc.date.parse(value + " " + item.`harvest time`, "ms", "yyyy-MM-dd HH:mm") '
	#	'				END '
	#	' ) '
	#	' FOREACH (n IN CASE '
	#	'	WHEN r.value = value '
	#	'	AND r.value IS NOT NULL '
	#	'	AND source_sample IS NULL '
	#	'	AND feature.name_lower = "harvest time" '
	#	'	AND item.`harvest time` IS NULL '
	#	'	THEN [1] ELSE [] END | '
	#	'		SET '
	#	'			item.`harvest time` = value, '
	#	'			item.time = CASE '
	#	'				WHEN item.`harvest date` IS NULL '
	#	'				THEN null '
	#	'				ELSE apoc.date.parse(item.`harvest date` + " " + value, "ms", "yyyy-MM-dd HH:mm") '
	#	'				END '
	#	' ) '
	#	# now set item properties
	#	# if custom ID set custom id property but only if no current property.
	#	' SET item.custom_id = CASE '
	#	'	WHEN r.value = value '
	#	'	AND r.value IS NOT NULL '
	#	'	AND feature.name_lower = "custom id" '
	#	'	THEN toString(r.value) '
	#	'	ELSE item.custom_id '
	#	'	END '
	#	# sample properties
	#	# - tissue
	#	' SET item.tissue = CASE '
	#	'	WHEN r.value = value '
	#	'	AND r.value IS NOT NULL '
	#	'	AND feature.name_lower = "tissue type" '
	#	'	THEN toString(r.value) '
	#	'	ELSE item.tissue '
	#	'	END '
	#	' WITH '
	#	'	field, item, feature, value, r, record_type '
	#	' MATCH '
	#	'	(partner:Partner) '
	#	'	<-[:AFFILIATED {data_shared: True}]-(user:User)'
	#	'	-[:SUBMITTED*..7]->()-[submitted:SUBMITTED]->(r) '
	#	# need to check for permissions for values that didn't merge to provide filtered feedback
	#	# and optionally roll back if existing records overlap without access confirmed.
	#	' OPTIONAL MATCH '
	#	'	(p)<-[access: AFFILIATED {confirmed: True}]-(:User {username_lower:toLower(trim($username))}) '
	#	# And give the user feedback on their submission
	#	' RETURN { '
	#	'	found: r.found, '
	#	'	submitted_by: user.name, '
	#	'	submitted_at: submitted.time, '
	#	'	value: r.value, '
	#	'	replicate: r.replicate, '
	#	'	uploaded_value: value, '
	#	'	uid: item.uid, '
	#	'	feature: feature.name, '
	#	'	`Time/Period`: CASE '
	#	'		WHEN record_type = "trait" THEN r.time '
	#	'		WHEN record_type = "condition" THEN [r.start, r.end] '
	#	'		ELSE Null '
	#	'		END, '
	#	'	access: access.confirmed, '
	#	'	partner: partner.name, '
	#	'	timestamp: r.timestamp, '
	#	'	text_date: r.text_date, '
	#	'	text_time: r.text_time, '
	#	'	text_start_date: r.text_start_date, '
	#	'	text_start_time: r.text_start_time, '
	#	'	text_end_date: r.text_end_date, '
	#	'	text_end_time: r.text_end_time '
	#	' } '
	#	'	ORDER BY feature.name_lower, field.uid, item.id, r.replicate '
	#)
	# generic upload to handle mixed UID (multiple levels) in csv in database format
	upload_fb_check = (
	#	' LOAD CSV WITH HEADERS FROM $filename as csvLine '
	#	' WITH '
	#	'	split(trim(toUpper(csvLine.uid)), ".")[0] as uid, '
	#	'	trim(toLower(csvLine.trait)) as trait_name_lower, '
	#	'	trim(csvLine.value) as value '
	#	# Identify the items and traits assessed
	#	' OPTIONAL MATCH '
	#	'	(item: Item { '
	#	'		uid: '
	#	'			CASE '
	#	'				WHEN size(split(uid, "_")) = 1 '
	#	'					THEN toInteger(uid) '
	#	'				ELSE '
	#	'					uid '
	#	'				END '
	#	'	})'
	#	' OPTIONAL MATCH '
	#	'	(trait: Trait { '
	#	'		name_lower: trait_name_lower, '
	#	'		level: '
	#	'			CASE '
	#	'				WHEN split(uid, "_")[1] IS NULL '
	#	'					THEN "field" '
	#	'				WHEN left(split(uid, "_")[1],1) = "B" '
	#	'					THEN "block" '
	#	'				WHEN left(split(uid, "_")[1],1) = "T" '
	#	'					THEN "tree" '
	#	'				WHEN left(split(uid, "_")[1],1) = "R" '
	#	'					THEN "branch" '
	#	'				WHEN left(split(uid, "_")[1],1) = "L" '
	#	'					THEN "leaf" '
	#	'				WHEN left(split(uid, "_")[1],1) = "S" '
	#	'					THEN "sample" '
	#	'				END '
	#	'	}) '
	#	' 	WITH '
	#	'		CASE WHEN item IS NULL THEN False ELSE True END as item, '
	#	'		CASE WHEN trait IS NULL THEN False ELSE trait.name_lower END as trait, '
	#	'		trait.format as format, '
	#	'		trait.category_list as category_list, '
	#	'		CASE WHEN item IS NOT NULL AND trait IS NOT NULL '
	#	'			THEN '
	#	'				CASE WHEN ' + upload_check_value +
	#	'				IS NULL THEN False ELSE True END '
	#	'			ELSE False '
	#	'			END '
	#	'			as value '
	#	' RETURN { '
	#	'	uid: item, '
	#	'	trait: trait, '
	#	'	format: format,'
	#	'	category_list: category_list,'
	#	'	value: value '
	#	' } '
	)
	upload_fb = (
	#	# load in the csv
	#	' LOAD CSV WITH HEADERS FROM $filename as csvLine '
	#	' WITH '
	#	'	trim(csvLine.location) as location, '
	#	'	trim(csvLine.person) as person, '
	#	'	split(trim(toUpper(csvLine.uid)), ".")[0] as uid, '
	#	'	split(trim(toUpper(csvLine.uid)), ".")[1] as replicate, '
	#	'	toLower(trim(csvLine.trait)) as trait_name_lower, '
	#	'	csvLine.timestamp as timestamp, '
	#	'	trim(csvLine.value) as value, '
	#	'	apoc.date.parse(csvLine.timestamp, "ms", "yyyy-MM-dd HH:mm:sszzz") as time '
	#	# Identify the items and traits assessed
	#	' MATCH '
	#	'	(field:Field { '
	#	'		uid: toInteger(split(uid, "_")[0]) '
	#	'	}), '
	#	'	(item: Item { '
	#	'		uid: '
	#	'			CASE '
	#	'				WHEN size(split(uid, "_")) = 1 '
	#	'					THEN toInteger(uid) '
	#	'				ELSE '
	#	'					uid '
	#	'				END '
	#	'	}), '
	#	'	(trait: Trait { '
	#	'		name_lower: trait_name_lower, '
	#	'		level: '
	#	'			CASE '
	#	'				WHEN split(uid, "_")[1] IS NULL '
	#	'					THEN "field" '
	#	'				WHEN left(split(uid, "_")[1],1) = "B" '
	#	'					THEN "block" '
	#	'				WHEN left(split(uid, "_")[1],1) = "T" '
	#	'					THEN "tree" '
	#	'				WHEN left(split(uid, "_")[1],1) = "R" '
	#	'					THEN "branch" '
	#	'				WHEN left(split(uid, "_")[1],1) = "L" '
	#	'					THEN "leaf" '
	#	'				WHEN left(split(uid, "_")[1],1) = "S" '
	#	'					THEN "sample" '
	#	'				END '
	#	'	}) '
	#	'	WHERE size(value) > 0 '
	#	' WITH '
	#	'	field, item, trait, '
	#	'	person, time, replicate, '
	#	'	value, '
	#	# this is unique to FB uploads
	#	'	timestamp, '
	#	'	location, '
	#	# the following are nulls where table has values to allow shared code between formats
	#	'	null as text_time, '
	#	'	null as text_date '
	#	'	WHERE time IS NOT NULL '
	#	+ shared_upload_code
	)
	# Upload Table procedures

	upload_table_property_check = (
			' LOAD CSV WITH HEADERS FROM $filename as csvLine '
			' WITH '
			'	csvLine, '
			'	toInteger(csvLine.row_index) as row_index, '
			'	CASE '
			'		WHEN size(split(csvLine.uid, "_")) = 1 '
			'			THEN toInteger(csvLine.uid) '
			'		ELSE '
			'			toUpper(csvLine.uid) '
			'		END as uid, '
			'	CASE '
			'		WHEN size(split(csvLine.uid, "_")) = 1 '
			'			THEN "field" '
			'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "B" '
			'			THEN "block" '
			'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "T" '
			'			THEN "tree" '
			'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "S" '
			'			THEN "sample" '
			'		END as level '
			' OPTIONAL MATCH  '
			'	(item: Item { '
			'		uid: uid '
			'	}) '
			' UNWIND $features as feature_name '
			'	OPTIONAL MATCH '
			'		(:RecordType {'
			'			name_lower: "property" '
			'		}) '
			'		<-[:OF_TYPE]-(feature: Feature { '
			'			name_lower: toLower(feature_name) '
			'		})-[:AT_LEVEL]->(:ItemLevel { '
			'			name_lower: level '
			'		}) '
			'	WITH '
			'		row_index, '
			'		feature_name, '
			'		item, '
			'		feature, '
			'		csvLine[feature_name] as value '
			'	WHERE trim(csvLine[feature_name]) <> ""'
			'	OPTIONAL MATCH '
			'		(item)'
			'		<-[:FOR_ITEM]-(if: ItemFeature)'
			'		-[:FOR_FEATURE*..2]->(feature), '
			'		(if)'
			'		<-[:RECORD_FOR]-(r: Record) '
			'		<-[s: SUBMITTED]-(: UserFieldFeature) '
			'		<-[: SUBMITTED]-(: Records) '
			'		<-[: SUBMITTED]-(: Submissions) '
			'		<-[: SUBMITTED]-(u: User) '
			'		-[:AFFILIATED {data_shared: true}]->(p:Partner) '
			'	OPTIONAL MATCH '
			'		(p)<-[a: AFFILIATED]-(: User {username_lower: toLower($username)}) '
			'	WITH '
			'		row_index, '
			'		feature_name, '
			'		item, '
			'		feature, '
			+ upload_check_value +
			'		AS value, '
			'		CASE '
			'			WHEN a.confirmed '
			'			THEN r.value '
			'			ELSE CASE '
			'				WHEN r IS NOT NULL '
			'				THEN "ACCESS DENIED" '
			'				ELSE null '
			'				END '
			'			END AS r_value, '
			'		s.time AS submitted_at, '
			'		CASE WHEN a.confirmed THEN u.name ELSE p.name END AS user, '
			'		a.confirmed AS access '
			'	WHERE '
			'	( '
			'		item IS NULL '
			'		OR '
			'		feature IS NULL '
			'		OR '
			'		value IS NULL '
			'	) OR ( '
			'		a.confirmed <> True '
			'		OR'
			'		r.value <> value '
			'	) '
			' WITH '
			'	row_index, '
			'	item, '
			'	feature, '
			'	feature_name, '
			'	value, '
			'	COLLECT(DISTINCT({ '
			'		existing_value: toString(r_value), '
			'		submitted_at: submitted_at, '
			'		user: user, '
			'		access: access '
			'	})) as conflicts '
			' RETURN { '
			'	row_index: row_index, '
			'	input_feature: feature_name, '
			'	UID: item.uid, '
			'	feature: feature.name, '
			'	format: feature.format, '
			'	category_list: feature.category_list, '
			'	value: value, '
			'	conflicts: conflicts '
			' } '
			' ORDER BY row_index '
			' LIMIT 50 '
	)

	upload_table_trait_check = (
			' LOAD CSV WITH HEADERS FROM $filename as csvLine '
			' WITH '
			'	csvLine, '
			'	toInteger(csvLine.row_index) as row_index, '
			'	CASE '
			'		WHEN size(split(split(csvLine.uid, ".")[0], "_")) = 1 '
			'			THEN toInteger(split(csvLine.uid, ".")[0]) '
			'		ELSE '
			'			toUpper(split(csvLine.uid, ".")[0]) '
			'		END as uid, '
			'	coalesce(toInteger(split(trim(toUpper(csvLine.uid)), ".")[1]), 1) as replicate, '
			'	apoc.date.parse( '
			'		CASE '
			'			WHEN size(split(replace(csvLine.date, " ", ""), "-")) = 3 '
			'			AND size(split(replace(csvLine.date, " ", ""), "-")[0]) = 4 '
			'			AND size(split(replace(csvLine.date, " ", ""), "-")[1]) <=2 '
			'			AND size(split(replace(csvLine.date, " ", ""), "-")[1]) >=1 '
			'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[1]) >= 1 '
			'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[1]) <= 12 '
			'			AND size(split(replace(csvLine.date, " ", ""), "-")[2]) <=2 '
			'			AND size(split(replace(csvLine.date, " ", ""), "-")[2]) >=1 '
			'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[2]) >= 1 '
			'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[2]) <= 31 '
			'			THEN '
			'				replace(csvLine.date, " ", "") '
			'			ELSE '
			'				Null '
			'			END '
			'		+ " " + '
			'		CASE '
			'			WHEN size(split(replace(csvLine.time, " ", ""), ":")) = 2 '
			'			AND size(split(replace(csvLine.time, " ", ""), ":")[0]) <= 2 '
			'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[0]) <=24 '
			'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[0]) >= 0 '
			'			AND size(split(replace(csvLine.time, " ", ""), ":")[1]) <= 2 '
			'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[1]) <=60 '
			'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[1]) >=0 '
			'			THEN '
			'				replace(csvLine.time, " ", "") '
			'			ELSE '
			'				"12:00" '
			'			END '
			'		, "ms", "yyyy-MM-dd HH:mm") as time, '
			'	CASE '
			'		WHEN size(split(csvLine.uid, "_")) = 1 '
			'			THEN "field" '
			'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "B" '
			'			THEN "block" '
			'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "T" '
			'			THEN "tree" '
			'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "S" '
			'			THEN "sample" '
			'		END as level '
			' OPTIONAL MATCH  '
			'	(item: Item { '
			'		uid: uid '
			' }) '
			' UNWIND $features as feature_name '
			'	OPTIONAL MATCH '
			'		(:RecordType {'
			'			name_lower: $record_type '
			'		}) '
			'		<-[:OF_TYPE]-(feature: Feature { '
			'			name_lower: toLower(feature_name) '
			'		})-[:AT_LEVEL]->(:ItemLevel { '
			'			name_lower: level '
			'		}) '
			'	WITH '
			'		row_index, '
			'		feature_name, '
			'		item, replicate, '
			'		feature, '
			'		time, '
			'		csvLine[feature_name] as value '
			'	WHERE trim(csvLine[feature_name]) <> "" '
			'	OPTIONAL MATCH '
			'		(item)'
			'		<-[:FOR_ITEM]-(if: ItemFeature)'
			'		-[:FOR_FEATURE*..2]->(feature), '
			'		(if)'
			'		<-[:RECORD_FOR]-(r: Record { '
			'			replicate: replicate, '
			'			time: time '
			'		}) '
			'		<-[s: SUBMITTED]-(: UserFieldFeature) '
			'		<-[: SUBMITTED]-(: Records) '
			'		<-[: SUBMITTED]-(: Submissions) '
			'		<-[: SUBMITTED]-(u: User) '
			'		-[:AFFILIATED {data_shared: true}]->(p:Partner) '
			'	OPTIONAL MATCH '
			'		(p)<-[a: AFFILIATED]-(: User {username_lower: toLower($username)}) '
			'	WITH '
			'		row_index, '
			'		feature_name, '
			'		item, replicate, '
			'		feature, '
			'		time, '
			+ upload_check_value +
			'		AS value, '
			'		CASE '
			'			WHEN a.confirmed '
			'			THEN r.value '
			'			ELSE CASE '
			'				WHEN r IS NOT NULL '
			'				THEN "ACCESS DENIED" '
			'				ELSE null '
			'				END '
			'			END AS r_value, '
			'		s.time AS submitted_at, '
			'		CASE WHEN a.confirmed THEN u.name ELSE p.name END AS user, '
			'		a.confirmed AS access '
			'	WHERE '
			'	( '
			'		item IS NULL '
			'		OR '
			'		feature IS NULL '
			'		OR '
			'		value IS NULL '
			'		OR '
			'		a.confirmed <> True '
			'		OR'
			'		r.value <> value '
			'	) '
			' WITH '
			'	row_index, '
			'	feature_name, '
			'	item, replicate, '
			'	feature, '
			'	value, '
			'	COLLECT(DISTINCT({ '
			'		existing_value: toString(r_value), '
			'		submitted_at: submitted_at, '
			'		user: user, '
			'		access: access '
			'	})) as conflicts '
			' RETURN { '
			'	row_index: row_index, '
			'	input_feature: feature_name, '
			'	UID: item.uid, '
			'	replicate: replicate, '
			'	feature: feature.name, '
			'	format: feature.format, '
			'	category_list: feature.category_list, '
			'	value: value, '
			'	conflicts: conflicts '
			' } '
			' ORDER BY row_index '
			' LIMIT 50 '
	)

	upload_table_condition_check = (
		' LOAD CSV WITH HEADERS FROM $filename as csvLine '
		' WITH '
		'	csvLine, '
		'	toInteger(csvLine.row_index) as row_index, '
		'	CASE '
		'		WHEN size(split(csvLine.uid, "_")) = 1 '
		'			THEN toInteger(csvLine.uid) '
		'		ELSE '
		'			toUpper(csvLine.uid) '
		'		END as uid, '
		'	CASE '
		'		WHEN size(split(csvLine.uid, "_")) = 1 '
		'			THEN "field" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "B" '
		'			THEN "block" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "T" '
		'			THEN "tree" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "S" '
		'			THEN "sample" '
		'		END as level, '
		# start time from start date and start time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`start date`, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.`start date`, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`start time`, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.`start time`, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.`start time`, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.`start time`, " ", "") '
		'			ELSE '
		'				"00:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as start, '
		# end time from end date and end time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`end date`, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.`end date`, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`end time`, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.`end time`, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.`end time`, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.`end time`, " ", "") '
		'			ELSE '
		'				"24:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as end '
		' OPTIONAL MATCH  '
		'	(item: Item { '
		'		uid: uid '
		'	}) '
		' UNWIND $features as feature_name '
		'	OPTIONAL MATCH '
		'		(:RecordType {'
		'			name_lower: $record_type '
		'		}) '
		'		<-[:OF_TYPE]-(feature: Feature { '
		'			name_lower: toLower(feature_name) '
		'		})-[:AT_LEVEL]->(:ItemLevel { '
		'			name_lower: level '
		'		}) '
		'	WITH '
		'		row_index, '
		'		feature_name, '
		'		item, '
		'		feature, '
		'		start, end, '
		'		csvLine[feature_name] as value '
		'	WHERE trim(csvLine[feature_name]) <> "" '
		'	OPTIONAL MATCH '
		'		(item) '
		'		<-[:FOR_ITEM]-(if: ItemFeature) '
		'		-[:FOR_FEATURE*..2]->(feature), '
		'		(if) '
		'		<-[:RECORD_FOR]-(r: Record) '
		'		<-[s: SUBMITTED]-(: UserFieldFeature) '
		'		<-[: SUBMITTED]-(: Records) '
		'		<-[: SUBMITTED]-(: Submissions) '
		'		<-[: SUBMITTED]-(u: User) '
		'		-[:AFFILIATED {data_shared: true}]->(p:Partner) '
		'	OPTIONAL MATCH '
		'		(p)<-[a: AFFILIATED]-(: User {username_lower: toLower($username)}) '
		'	WITH '
		'		row_index, '
		'		feature_name, '
		'		item, '
		'		feature, '
		'		start, end, '
		+ upload_check_value +
		'		AS value, '
		'		CASE WHEN r.start <> False THEN r.start ELSE Null END AS r_start, '
		'		CASE WHEN r.end <> False THEN r.end ELSE Null END AS r_end, '
		'		CASE '
		'			WHEN a.confirmed '
		'			THEN r.value '
		'			ELSE CASE '
		'				WHEN r IS NOT NULL '
		'				THEN "ACCESS DENIED" '
		'				ELSE null '
		'				END '
		'			END AS r_value, '
		'		s.time AS submitted_at, '
		'		CASE WHEN a.confirmed THEN u.name ELSE p.name END AS user, '
		'		a.confirmed AS access '
		'	WHERE '
		'	( '
		'		item IS NULL '
		'		OR '
		'		feature IS NULL '
		'		OR '
		'		value IS NULL '
		'	) OR ( '
		# condition conflicts
		'	(	'
		'		a.confirmed <> True '
		'		OR '
		'		r.value <> value '
		'	) AND ( '
		# handle fully bound records
		# - any overlapping records
		'		( '
		'			r_start < end '
		'			AND '
		'			r_end > start '
		'		) OR ( '
		# - a record that has a lower bound in the bound period 
		'			r_start >= start '
		'			AND '
		'			r_start < end '
		'		) OR ( '
		# - a record that has an upper bound in the bound period
		'			r_end > start '
		'			AND '
		'			r_end <= end '
		'		) OR ( '
		# now handle lower bound only records
		'			end IS NULL '
		'			AND ( '
		'					( '
		# - existing bound period includes start
		'						r_end > start '
		'						AND '
		'						r_start <= start '
		# - record with same lower bound
		'					) OR ( '
		'						r_start = start '
		# - record with upper bound only greater than this lower bound
		'					) OR ( '
		'						r_start IS NULL '
		'						AND '
		'						r_end > start '
		'					)'
		'				) '
		'		) OR ( '
		# now handle upper bound only records 
		'			start IS NULL '
		'			AND ( '
		'					( '
		# - existing bound period includes end
		'						r_end >= end '
		'						AND '
		'						r_start < end '
		# - record with same upper bound
		'					) OR ( '
		'						r_end = end '
		# - record with lower bound only less than this upper bound
		'					) OR ( '
		'						r_end IS NULL '
		'						AND '
		'						r_start < end '
		'					) '
		'				)'
		'		) OR ( '
		# always conflict with unbound records
		'			r_end IS NULL '
		'			AND '
		'			r_start IS NULL '
		'		) '
		'	) '
		' ) '
		' WITH '
		'	row_index, '
		'	feature_name, '
		'	item, '
		'	feature, '
		'	value, '
		'	COLLECT(DISTINCT({ '
		'		start: r_start, '
		'		end: r_end, '
		'		existing_value: toString(r_value), '
		'		submitted_at: submitted_at, '
		'		user: user, '
		'		access: access '
		'	})) as conflicts '
		' RETURN { '
		'	row_index: row_index, '
		'	input_feature: feature_name, '
		'	UID: item.uid, '
		'	feature: feature.name, '
		'	format: feature.format, '
		'	category_list: feature.category_list, '
		'	value: value, '
		'	conflicts: conflicts '
		' } '
		' ORDER BY row_index '
		' LIMIT 50 '
	)

	upload_table_property = (
		' LOAD CSV WITH HEADERS FROM $filename as csvLine '
		' WITH '
		'	csvLine, '
		'	trim(csvLine.person) as person, '
		'	CASE '
		'		WHEN size(split(csvLine.uid, "_")) = 1 '
		'			THEN toInteger(csvLine.uid) '
		'		ELSE '
		'			toInteger(split(csvLine.uid, "_")[0]) '
		'		END as field_uid, '
		'	CASE '
		'		WHEN size(split(csvLine.uid, "_")) = 1 '
		'			THEN toInteger(csvLine.uid) '
		'		ELSE '
		'			toUpper(csvLine.uid) '
		'		END as uid, '
		'	CASE '
		'		WHEN size(split(csvLine.uid, "_")) = 1 '
		'			THEN "field" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "B" '
		'			THEN "block" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "T" '
		'			THEN "tree" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "S" '
		'			THEN "sample" '
		'		END as level '
		' MATCH  '
		'	(field:Field { '
		'		uid: field_uid '
		'	}), '
		'	(item: Item { '
		'		uid: uid '
		'	}) '
		' UNWIND $features as feature_name '
		'	MATCH '
		'		(:RecordType {'
		'			name_lower: $record_type '
		'		}) '
		'		<-[:OF_TYPE]-(feature: Feature { '
		'			name_lower: toLower(feature_name) '
		'		})-[:AT_LEVEL]->(item_level: ItemLevel { '
		'			name_lower: level '
		'		}) '
		# Check for data in table  
		'	WHERE trim(csvLine[feature_name]) <> "" '
		'	WITH '
		'		field, '
		'		item, '
		'		feature, '
		'		level, '
		'		person, '
		'		csvLine[feature_name] as value '
		'	FOREACH (n in CASE '
		'		WHEN level = "field" '
		'			THEN [1] ELSE [] END | '
		'				MERGE '
		'					(item)<-[: FOR_ITEM]-(:ItemFeature)-[: FOR_FEATURE]->(feature) '
		'	) '
		'	FOREACH (n in CASE '
		'		WHEN level in ["block", "tree", "sample"] '
		'			THEN [1] ELSE [] END | '
		'				MERGE '
		'					(field)<-[: FROM_FIELD]-(field_feature: FieldFeature)-[: FOR_FEATURE]->(feature) '
		'				MERGE '
		'					(item)<-[: FOR_ITEM]-(:ItemFeature)-[: FOR_FEATURE]->(field_feature) '
		'	) '
		'	WITH '
		'		field, '
		'		item, '
		'		feature, '
		'		person, '
		+ upload_check_value +
		'		AS value '
		'	WHERE value IS NOT NULL '
		# get the user submission tracking nodes
		'	MATCH '
		'		(:User { '
		'			username_lower : toLower(trim($username))'
		'		}) '
		'		-[: SUBMITTED]->(: Submissions) '
		'		-[: SUBMITTED]->(data_sub: Records) '
		# and the item/feature node
		'	MATCH '
		'		(item) '
		'		<-[: FOR_ITEM]-(item_feature: ItemFeature) '
		'		-[ :FOR_FEATURE*..2]->(feature) '
		'	OPTIONAL MATCH '
		'		(field_feature: FieldFeature) '
		'		<-[: FOR_FEATURE]-(item_feature) '
		'	MERGE '
		'		(r: Record) '
		'		-[: RECORD_FOR]->(item_feature) '
		'		ON MATCH SET '
		'			r.found = True '
		'		ON CREATE SET '
		'			r.found = False, '
		'			r.person = person, '
		'			r.value = CASE '
		'	 			WHEN feature.format <> "multicat" THEN value '
		'				ELSE extract(i in FILTER (n in split(value, ":") WHERE  size(n) > 0 )| toLower(trim(i)))'
		'				END '
		# additional statements to occur when new data point
		'	 FOREACH (n IN CASE '
		'		WHEN r.found = False '
		'			THEN [1] ELSE [] END | '
		# track user submissions through /User/FieldFeature container
		'				MERGE '
		'					(data_sub)'
		'					-[:SUBMITTED]->(uff:UserFieldFeature) '
		'					-[:CONTRIBUTED]->(field_feature) '
		# then finally the data with a timestamp
		'				MERGE '
		'					(uff)-[s1:SUBMITTED]->(r) '
		'					ON CREATE SET '
		'						s1.time = timestamp() '
		'	) '
		'	WITH '
		'		field, '
		'		item, '
		'		feature, '
		'		value, '
		'		r '
		'	MATCH '
		'		(partner:Partner) '
		'		<-[:AFFILIATED {data_shared: True}]-(user:User) '
		'		-[:SUBMITTED]->(:Submissions) '
		'		-[:SUBMITTED]->(:Records) '
		'		-[:SUBMITTED]->(:UserFieldFeature) '
		'		-[submitted:SUBMITTED]->(r) '
		# need to check for permissions for values that didn't merge to provide filtered feedback
		# and optionally roll back if existing records overlap without access confirmed.
		'	OPTIONAL MATCH '
		'		(partner)<-[access: AFFILIATED {confirmed: True}]-(:User {username_lower:toLower(trim($username))}) '
		# And give the user feedback on their submission
		'	RETURN { '
		'		found: r.found, '
		'		submitted_by: CASE WHEN access IS NOT NULL THEN user.name ELSE partner.name END, '
		'		submitted_at: submitted.time, '
		'		value: CASE '
		'			WHEN NOT r.found '
		'			THEN r.value '
		'			WHEN access IS NOT NULL '
		'			THEN r.value '
		'			ELSE "ACCESS DENIED" '
		'			END, '
		'		uploaded_value: value, '
		'		access: CASE WHEN access IS NULL THEN False ELSE True END, '
		'		uid: item.uid, '
		'		feature: feature.name, '
		'		partner: partner.name '
		'	} '
		'	ORDER BY feature.name_lower, field.uid, item.id '
	)

	upload_table_trait = (
		' LOAD CSV WITH HEADERS FROM $filename as csvLine '
		' WITH '
		'	csvLine, '
		'	trim(csvLine.person) as person, '
		'	CASE '
		'		WHEN size(split(csvLine.uid, "_")) = 1 '
		'			THEN toInteger(csvLine.uid) '
		'		ELSE '
		'			toInteger(split(csvLine.uid, "_")[0]) '
		'		END as field_uid, '
		'	CASE '
		'		WHEN size(split(split(csvLine.uid, ".")[0], "_")) = 1 '
		'			THEN toInteger(split(csvLine.uid, ".")[0]) '
		'		ELSE '
		'			toUpper(split(csvLine.uid, ".")[0]) '
		'		END as uid, '
		'	coalesce(toInteger(split(trim(toUpper(csvLine.uid)), ".")[1]), 1) as replicate, '
		# time from date and time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.date, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.date, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.date, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.time, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.time, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.time, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.time, " ", "") '
		'			ELSE '
		'				"12:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as time, '
		'	CASE '
		'		WHEN size(split(csvLine.uid, "_")) = 1 '
		'			THEN "field" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "B" '
		'			THEN "block" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "T" '
		'			THEN "tree" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "S" '
		'			THEN "sample" '
		'		END as level '
		# And identify the fields and features assessed
		' MATCH  '
		'	(field:Field { '
		'		uid: field_uid '
		'	}), '
		'	(item: Item { '
		'		uid: uid '
		'	}) '
		' UNWIND $features as feature_name '
		'	MATCH '
		'		(:RecordType {'
		'			name_lower: $record_type '
		'		}) '
		'		<-[:OF_TYPE]-(feature: Feature { '
		'			name_lower: toLower(feature_name) '
		'		})-[:AT_LEVEL]->(item_level: ItemLevel { '
		'			name_lower: level '
		'		}) '  
		# Check for data in table  
		'	WHERE trim(csvLine[feature_name]) <> "" '
		'	WITH '
		'		field, '
		'		item, '
		'		feature, '
		'		level, '
		'		person, '
		'		time, '
		'		replicate, '
		'		csvLine[feature_name] as value, '
		# to allow differentiation of defaulted time and set time
		' 		csvLine.time as text_time '
		# for trait data if no time is set then drop the row 
		'	WHERE '
		'		time IS NOT NULL '
		'	FOREACH (n in CASE '
		'		WHEN level = "field" '
		'			THEN [1] ELSE [] END | '
		'				MERGE '
		'					(item)<-[: FOR_ITEM]-(:ItemFeature)-[: FOR_FEATURE]->(feature) '
		'	) '
		'	FOREACH (n in CASE '
		'		WHEN level in ["block", "tree", "sample"] '
		'			THEN [1] ELSE [] END | '
		'				MERGE '
		'					(field)<-[: FROM_FIELD]-(field_feature: FieldFeature)-[: FOR_FEATURE]->(feature) '
		'				MERGE '
		'					(item)<-[: FOR_ITEM]-(:ItemFeature)-[: FOR_FEATURE]->(field_feature) '
		'	) '
		'	WITH '
		'		field, '
		'		item, '
		'		feature, '
		'		level, '
		'		person, '
		'		time, '
		'		replicate, '
		'		text_time, '
		+ upload_check_value +
		'		AS value '
		'	WHERE value IS NOT NULL '
		# get the user submission tracking nodes
		'	MATCH '
		'		(:User { '
		'			username_lower : toLower(trim($username))'
		'		}) '
		'		-[: SUBMITTED]->(: Submissions) '
		'		-[: SUBMITTED]->(data_sub: Records) '
		# and the item/feature node
		'	MATCH '
		'		(item) '
		'		<-[: FOR_ITEM]-(item_feature: ItemFeature)'
		'		-[ :FOR_FEATURE*..2]->(feature) '
		'	OPTIONAL MATCH '
		'		(field_feature: FieldFeature) '
		'		<-[: FOR_FEATURE]-(item_feature) '
		'	MERGE '
		'		(r: Record { '
		'			time : time, '
		'			replicate: replicate '
		'		}) '
		'		-[:RECORD_FOR]->(item_feature) '
		'		ON MATCH SET '
		'			r.found = True '
		'		ON CREATE SET '
		'			r.found = False, '
		'			r.person = person, '
		'			r.text_time = text_time, '
		'			r.value = CASE '
		' 				WHEN feature.format <> "multicat" THEN value '
		'				ELSE extract(i in FILTER (n in split(value, ":") WHERE  size(n) > 0 )| toLower(trim(i)))'
		'				END '
		# additional statements to occur when new data point
		'	FOREACH (n IN CASE '
		'		WHEN r.found = False '
		'			THEN [1] ELSE [] END | '
		# track user submissions through /User/FieldFeature container
		'				MERGE '
		'					(data_sub)'
		'					-[:SUBMITTED]->(uff:UserFieldFeature) '
		'					-[:CONTRIBUTED]->(field_feature) '
		# then finally the data with a timestamp
		'				MERGE '
		'					(uff)-[s1:SUBMITTED]->(r) '
		'					ON CREATE SET '
		'						s1.time = timestamp() '
		' ) '
		'	WITH '
		'		field, '
		'		item, '
		'		feature, '
		'		value, '
		'		r '
		'	MATCH '
		'		(partner:Partner) '
		'		<-[:AFFILIATED {data_shared: True}]-(user:User) '
		'		-[:SUBMITTED]->(:Submissions) '
		'		-[:SUBMITTED]->(:Records) '
		'		-[:SUBMITTED]->(:UserFieldFeature) '
		'		-[submitted:SUBMITTED]->(r) '
		# need to check for permissions for values that didn't merge to provide filtered feedback
		# and optionally roll back if existing records overlap without access confirmed.
		'	OPTIONAL MATCH '
		'	(partner)<-[access: AFFILIATED {confirmed: True}]-(:User {username_lower:toLower(trim($username))}) '
		# And give the user feedback on their submission
		'	RETURN { '
		'		found: r.found, '
		'		submitted_by: CASE WHEN access IS NOT NULL THEN user.name ELSE partner.name END, '
		'		submitted_at: submitted.time, '
		'		value: CASE '
		'			WHEN NOT r.found '
		'			THEN r.value '
		'			WHEN access IS NOT NULL '
		'			THEN r.value '
		'			ELSE "ACCESS DENIED" '
		'			END, '
		'		uploaded_value: value, '
		'		access: CASE WHEN access IS NULL THEN False ELSE True END, '
		'		replicate: r.replicate, '
		'		`Time/Period`: r.time, '
		'		uid: item.uid, '
		'		feature: feature.name, '
		'		partner: partner.name '
		' } '
		'	ORDER BY feature.name_lower, field.uid, item.id, r.replicate '
	)

	upload_table_condition = (
		# load in the csv
		' LOAD CSV WITH HEADERS FROM $filename as csvLine '
		' WITH '
		'	csvLine, '
		'	trim(csvLine.person) as person, '
		'	CASE '
		'		WHEN size(split(csvLine.uid, "_")) = 1 '
		'			THEN toInteger(csvLine.uid) '
		'		ELSE '
		'			toInteger(split(csvLine.uid, "_")[0]) '
		'		END as field_uid, '
		'	CASE '
		'		WHEN size(split(csvLine.uid, "_")) = 1 '
		'			THEN toInteger(csvLine.uid) '
		'		ELSE '
		'			toUpper(csvLine.uid) '
		'		END as uid, '
		'	CASE '
		'		WHEN size(split(csvLine.uid, "_")) = 1 '
		'			THEN "field" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "B" '
		'			THEN "block" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "T" '
		'			THEN "tree" '
		'		WHEN toUpper(left(split(csvLine.uid, "_")[1],1)) = "S" '
		'			THEN "sample" '
		'		END as level, '
		# start time from start date and start time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`start date`, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.`start date`, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`start time`, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.`start time`, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.`start time`, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.`start time`, " ", "") '
		'			ELSE '
		'				"00:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as start, '
		# end time from end date and end time
		'	apoc.date.parse( '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`end date`, " ", ""), "-")) = 3 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[0]) = 4 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[1]) <=2 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[1]) >=1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[1]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[1]) <= 12 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[2]) <=2 '
		'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[2]) >=1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[2]) >= 1 '
		'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[2]) <= 31 '
		'			THEN '
		'				replace(csvLine.`end date`, " ", "") '
		'			ELSE '
		'				Null '
		'			END '
		'		+ " " + '
		'		CASE '
		'			WHEN size(split(replace(csvLine.`end time`, " ", ""), ":")) = 2 '
		'			AND size(split(replace(csvLine.`end time`, " ", ""), ":")[0]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[0]) <=24 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[0]) >= 0 '
		'			AND size(split(replace(csvLine.`end time`, " ", ""), ":")[1]) <= 2 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[1]) <=60 '
		'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[1]) >=0 '
		'			THEN '
		'				replace(csvLine.`end time`, " ", "") '
		'			ELSE '
		'				"24:00" '
		'			END '
		'		, "ms", "yyyy-MM-dd HH:mm") as end '
		# And identify the fields and features assessed
		' MATCH  '
		'	(field:Field { '
		'		uid: field_uid '
		'	}), '
		'	(item: Item { '
		'		uid: uid '
		'	}) '
		' UNWIND $features as feature_name '
		'	MATCH '
		'		(:RecordType {'
		'			name_lower: $record_type '
		'		}) '
		'		<-[:OF_TYPE]-(feature: Feature { '
		'			name_lower: toLower(feature_name) '
		'		})-[:AT_LEVEL]->(item_level:ItemLevel { '
		'			name_lower: level '
		'		}) '
		# Check for data in table
		'	WHERE trim(csvLine[feature_name]) <> "" '
		'	WITH '
		'		field, '
		'		item, '
		'		feature, '
		'		level, '
		'		person, '
		'		start, end, '
		'		csvLine[feature_name] as value, '
		# to allow differentiation of defaulted time and set time
		'		csvLine.`start time` as text_start_time, '
		'		csvLine.`end time` as text_end_time '
		'	FOREACH (n in CASE '
		'		WHEN level = "field" '
		'			THEN [1] ELSE [] END | '
		'				MERGE '
		'					(item)<-[: FOR_ITEM]-(:ItemFeature)-[: FOR_FEATURE]->(feature) '
		'	) '
		'	FOREACH (n in CASE '
		'		WHEN level in ["block", "tree", "sample"] '
		'			THEN [1] ELSE [] END | '
		'				MERGE '
		'					(field)<-[: FROM_FIELD]-(field_feature: FieldFeature)-[: FOR_FEATURE]->(feature) '
		'				MERGE '
		'					(item)<-[: FOR_ITEM]-(:ItemFeature)-[: FOR_FEATURE]->(field_feature) '
		'	) '
		'	WITH '
		'		field, '
		'		item, '
		'		feature, '
		'		level, '
		'		person, '
		'		start, end, '
		'		text_start_time, text_end_time, '
		+ upload_check_value +
		'		AS value '
		'	WHERE value IS NOT NULL '
		# get the user submission tracking nodes
		'	MATCH '
		'		(:User { '
		'			username_lower : toLower(trim($username))'
		'		}) '
		'		-[: SUBMITTED]->(: Submissions) '
		'		-[: SUBMITTED]->(data_sub: Records) '
		# and the item/feature node
		'	MATCH '
		'		(item) '
		'		<-[: FOR_ITEM]-(item_feature: ItemFeature)'
		'		-[ :FOR_FEATURE*..2]->(feature) '
		'	OPTIONAL MATCH '
		'		(field_feature: FieldFeature) '
		'		<-[: FOR_FEATURE]-(item_feature) '
		'	MERGE '
		'		(r: Record { '
		'			start : CASE WHEN start IS NOT NULL THEN start ELSE False END, '
		'			end : CASE WHEN end IS NOT NULL THEN end ELSE False END '
		'		}) '
		'		-[:RECORD_FOR]->(item_feature) '
		'		ON MATCH SET '
		'			r.found = True '
		'		ON CREATE SET '
		'			r.found = False, '
		'			r.person = person, '
		'			r.text_start_time = text_start_time, '
		'			r.text_end_time = text_end_time, '
		'			r.value = CASE '
		' 				WHEN feature.format <> "multicat" THEN value '
		'				ELSE extract(i in FILTER (n in split(value, ":") WHERE  size(n) > 0 )| toLower(trim(i)))'
		'				END '
		# additional statements to occur when new data point
		'	FOREACH (n IN CASE '
		'		WHEN r.found = False '
		'			THEN [1] ELSE [] END | '
		# track user submissions through /User/FieldFeature container
		'				MERGE '
		'					(data_sub)'
		'					-[:SUBMITTED]->(uff:UserFieldFeature) '
		'					-[:CONTRIBUTED]->(field_feature) '
		# then finally the data with a timestamp
		'				MERGE '
		'					(uff)-[s1:SUBMITTED]->(r) '
		'					ON CREATE SET '
		'						s1.time = timestamp() '
		' ) '
		'	WITH '
		'		field, '
		'		item, '
		'		feature, '
		'		item_feature, '
		'		value, '
		'		r, '
		'		start, end '
		'	MATCH '
		'		(partner:Partner) '
		'		<-[:AFFILIATED {data_shared: True}]-(user:User) '
		'		-[:SUBMITTED]->(:Submissions) '
		'		-[:SUBMITTED]->(:Records) '
		'		-[:SUBMITTED]->(:UserFieldFeature) '
		'		-[submitted:SUBMITTED]->(r) '
		# need to check for permissions for values that didn't merge to provide filtered feedback
		# and optionally roll back if existing records overlap without access confirmed.
		'	OPTIONAL MATCH '
		'	(partner)<-[access: AFFILIATED {confirmed: True}]-(:User {username_lower:toLower(trim($username))}) '
		# check again for conflicts - in case there have been concurrent submissions 
		# or there are conflicts within the uploaded table
		'	OPTIONAL MATCH '
		'		(r)'
		'		-[:RECORD_FOR]->(item_feature) '
		'		<-[:RECORD_FOR]-(rr:Record) '
		'		<-[rr_sub:SUBMITTED]-(:UserFieldFeature) '
		'		<-[:SUBMITTED]-(:Records) '
		'		<-[:SUBMITTED]-(:Submissions) '
		'		<-[:SUBMITTED]-(rr_user:User) '
		'		-[:AFFILIATED {data_shared: True}]->(rr_partner:Partner) '
		'	WHERE '
		'		( '
		# handle fully bound records
		# - any overlapping records
		'			CASE WHEN rr.start <> False THEN rr.start ELSE Null END < end '
		'			AND '
		'			CASE WHEN rr.end <> False THEN rr.end ELSE Null END > start '
		'		) OR ( '
		# - a record that has a lower bound in the bound period 
		'			CASE WHEN rr.start <> False THEN rr.start ELSE Null END >= start '
		'			AND '
		'			CASE WHEN rr.start <> False THEN rr.start ELSE Null END < end '
		'		) OR ( '
		# - a record that has an upper bound in the bound period
		'			CASE WHEN  rr.end <> False THEN rr.end ELSE Null END > start '
		'			AND '
		'			CASE WHEN rr.end <> False THEN rr.end ELSE Null END <= end '
		'		) OR ( '
		# now handle lower bound only records
		'			end IS NULL '
		'			AND ( '
		# - existing bound period includes start
		'				CASE WHEN rr.end <> False THEN rr.end ELSE Null END > start '
		'				AND '
		'				CASE WHEN rr.start <> False THEN rr.start ELSE Null END <= start '
		# - record with same lower bound
		'			) OR ( '
		'				rr.start = start '
		# - record with upper bound only greater than this lower bound
		'			) OR ( '
		'				rr.start = False '
		'				AND '
		'				CASE WHEN rr.end <> False THEN rr.end ELSE Null END > start '
		'			) '
		'		) OR ( '
		# now handle upper bound only records 
		'			start IS NULL '
		'			AND ( '
		# - existing bound period includes end
		'				CASE WHEN rr.end <> False THEN rr.end ELSE Null END >= end '
		'				AND '
		'				CASE WHEN rr.start <> False THEN rr.start ELSE Null END < end '
		# - record with same upper bound
		'			) OR ( '
		'				rr.end = end '
		# - record with lower bound only less than this upper bound
		'			) OR ( '
		'				rr.end = False '
		'				AND '
		'				CASE WHEN rr.start <> False THEN rr.start ELSE Null END < end '
		'			) '
		'		) OR ( '
		# always conflict with unbound records
		'			rr.end = False '
		'			AND '
		'			rr.start = False '
		'		)'
		'	OPTIONAL MATCH '
		'		(rr_partner) '
		'		<-[rr_access: AFFILIATED {confirmed: True}]-(:User {username_lower: toLower(trim($username))}) '
		# If don't have access or if have access and values don't match then potential conflict 
		# time parsing to allow various degrees of specificity in the relevant time range is below
		'	WITH '
		'		r, '
		'		access, '
		'		user, '
		'		partner, '
		'		value, '
		'		submitted, '
		'		item, '
		'		field, '
		'		feature, '
		'		case WHEN rr IS NOT NULL AND (rr.value <> r.value OR rr_access IS NULL) THEN '
		'			collect(DISTINCT { '
		'				start: rr.start, '
		'				end: rr.end, '
		'				existing_value: CASE WHEN rr_access IS NOT NULL THEN toString(rr.value) ELSE "ACCESS DENIED" END, '
		'				submitted_at: rr_sub.time, '
		'				user: CASE WHEN rr_access IS NOT NULL THEN rr_user.name ELSE rr_partner.name END, '
		'				access: CASE WHEN rr_access IS NOT NULL THEN True ELSE False END '
		'			}) '
		'			ELSE Null END as conflicts '
		# And give the user feedback on their submission
		'	RETURN { '
		'		found: r.found, '
		'		submitted_by: CASE WHEN access IS NOT NULL THEN user.name ELSE partner.name END, '
		'		submitted_at: submitted.time, '
		'		value: CASE '
		'			WHEN NOT r.found '
		'			THEN r.value '
		'			WHEN access IS NOT NULL '
		'			THEN r.value '
		'			ELSE "ACCESS DENIED" '
		'			END, '
		'		uploaded_value: value, '
		'		access: CASE WHEN access IS NULL THEN False ELSE True END, '
		'		`Time/Period`: [r.start, r.end], '
		'		uid: item.uid, '
		'		feature: feature.name, '
		'		partner: partner.name, '
		'		conflicts: conflicts '
		' } '
		'	ORDER BY feature.name_lower, field.uid, item.id  '
	)

	#upload_table = (
	#	# load in the csv
	#	' LOAD CSV WITH HEADERS FROM $filename as csvLine '
	#	' WITH '
	#	'	csvLine, '
	#	'	trim(csvLine.person) as person, '
	#	'	split(trim(toUpper(csvLine.uid)), ".")[0] as uid, '
	#	'	toInteger(split(trim(toUpper(csvLine.uid)), ".")[1]) as replicate, '
	#	'	CASE '
	#	'		WHEN "time" IN keys(csvLine) THEN "trait" '
	#	'		WHEN "start time" IN keys(csvLine) THEN "condition" '
	#	'		ELSE "property" END as record_type, '
	#	# time from date and time
	#	'	apoc.date.parse( '
	#	'		CASE '
	#	'			WHEN size(split(replace(csvLine.date, " ", ""), "-")) = 3 '
	#	'			AND size(split(replace(csvLine.date, " ", ""), "-")[0]) = 4 '
	#	'			AND size(split(replace(csvLine.date, " ", ""), "-")[1]) <=2 '
	#	'			AND size(split(replace(csvLine.date, " ", ""), "-")[1]) >=1 '
	#	'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[1]) >= 1 '
	#	'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[1]) <= 12 '
	#	'			AND size(split(replace(csvLine.date, " ", ""), "-")[2]) <=2 '
	#	'			AND size(split(replace(csvLine.date, " ", ""), "-")[2]) >=1 '
	#	'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[2]) >= 1 '
	#	'			AND toInteger(split(replace(csvLine.date, " ", ""), "-")[2]) <= 31 '
	#	'			THEN '
	#	'				replace(csvLine.date, " ", "") '
	#	'			ELSE '
	#	'				Null '
	#	'			END '
	#	'		+ " " + '
	#	'		CASE '
	#	'			WHEN size(split(replace(csvLine.time, " ", ""), ":")) = 2 '
	#	'			AND size(split(replace(csvLine.time, " ", ""), ":")[0]) <= 2 '
	#	'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[0]) <=24 '
	#	'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[0]) >= 0 '
	#	'			AND size(split(replace(csvLine.time, " ", ""), ":")[1]) <= 2 '
	#	'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[1]) <=60 '
	#	'			AND toInteger(split(replace(csvLine.time, " ", ""), ":")[1]) >=0 '
	#	'			THEN '
	#	'				replace(csvLine.time, " ", "") '
	#	'			ELSE '
	#	'				"12:00" '
	#	'			END '
	#	'		, "ms", "yyyy-MM-dd HH:mm") as time, '
	#	# start time from start date and start time
	#	'	apoc.date.parse( '
	#	'		CASE '
	#	'			WHEN size(split(replace(csvLine.`start date`, " ", ""), "-")) = 3 '
	#	'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[0]) = 4 '
	#	'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[1]) <=2 '
	#	'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[1]) >=1 '
	#	'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[1]) >= 1 '
	#	'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[1]) <= 12 '
	#	'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[2]) <=2 '
	#	'			AND size(split(replace(csvLine.`start date`, " ", ""), "-")[2]) >=1 '
	#	'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[2]) >= 1 '
	#	'			AND toInteger(split(replace(csvLine.`start date`, " ", ""), "-")[2]) <= 31 '
	#	'			THEN '
	#	'				replace(csvLine.`start date`, " ", "") '
	#	'			ELSE '
	#	'				Null '
	#	'			END '
	#	'		+ " " + '
	#	'		CASE '
	#	'			WHEN size(split(replace(csvLine.`start time`, " ", ""), ":")) = 2 '
	#	'			AND size(split(replace(csvLine.`start time`, " ", ""), ":")[0]) <= 2 '
	#	'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[0]) <=24 '
	#	'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[0]) >= 0 '
	#	'			AND size(split(replace(csvLine.`start time`, " ", ""), ":")[1]) <= 2 '
	#	'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[1]) <=60 '
	#	'			AND toInteger(split(replace(csvLine.`start time`, " ", ""), ":")[1]) >=0 '
	#	'			THEN '
	#	'				replace(csvLine.`start time`, " ", "") '
	#	'			ELSE '
	#	'				"00:00" '
	#	'			END '
	#	'		, "ms", "yyyy-MM-dd HH:mm") as start, '
	#	# end time from end date and end time
	#	'	apoc.date.parse( '
	#	'		CASE '
	#	'			WHEN size(split(replace(csvLine.`end date`, " ", ""), "-")) = 3 '
	#	'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[0]) = 4 '
	#	'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[1]) <=2 '
	#	'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[1]) >=1 '
	#	'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[1]) >= 1 '
	#	'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[1]) <= 12 '
	#	'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[2]) <=2 '
	#	'			AND size(split(replace(csvLine.`end date`, " ", ""), "-")[2]) >=1 '
	#	'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[2]) >= 1 '
	#	'			AND toInteger(split(replace(csvLine.`end date`, " ", ""), "-")[2]) <= 31 '
	#	'			THEN '
	#	'				replace(csvLine.`end date`, " ", "") '
	#	'			ELSE '
	#	'				Null '
	#	'			END '
	#	'		+ " " + '
	#	'		CASE '
	#	'			WHEN size(split(replace(csvLine.`end time`, " ", ""), ":")) = 2 '
	#	'			AND size(split(replace(csvLine.`end time`, " ", ""), ":")[0]) <= 2 '
	#	'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[0]) <=24 '
	#	'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[0]) >= 0 '
	#	'			AND size(split(replace(csvLine.`end time`, " ", ""), ":")[1]) <= 2 '
	#	'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[1]) <=60 '
	#	'			AND toInteger(split(replace(csvLine.`end time`, " ", ""), ":")[1]) >=0 '
	#	'			THEN '
	#	'				replace(csvLine.`end time`, " ", "") '
	#	'			ELSE '
	#	'				"24:00" '
	#	'			END '
	#	'		, "ms", "yyyy-MM-dd HH:mm") as end '
	#	# And identify the fields and features assessed
	#	' MATCH  '
	#	'	(field:Field { '
	#	'		uid: toInteger(split(uid, "_")[0]) '
	#	'	}), '
	#	'	(item: Item { '
	#	'		uid: '
	#	'			CASE '
	#	'				WHEN size(split(uid, "_")) = 1 '
	#	'					THEN toInteger(uid) '
	#	'				ELSE '
	#	'					toUpper(uid) '
	#	'				END '
	#	'	}) '
	#	' UNWIND $features as feature_name '
	#	'	MATCH '
	#	'		(:RecordType {'
	#	'			name_lower: record_type '
	#	'		}) '
	#	'		<-[:OF_TYPE]-(feature: Feature { '
	#	'			name_lower: toLower(feature_name) '
	#	'		})-[:AT_LEVEL]->(item_level:ItemLevel { '
	#	'			name_lower: '
	#	'				CASE '
	#	'					WHEN split(uid, "_")[1] IS NULL '
	#	'						THEN "field" '
	#	'					WHEN toUpper(left(split(uid, "_")[1],1)) = "B" '
	#	'						THEN "block" '
	#	'					WHEN toUpper(left(split(uid, "_")[1],1)) = "T" '
	#	'						THEN "tree" '
	#	'					WHEN toUpper(left(split(uid, "_")[1],1)) = "S" '
	#	'						THEN "sample" '
	#	'					END '
	#	'		}) '
	#	# Check for data in table
	#	# all load_csv values are string so can just check size after trimming whitespace
	#	'	WHERE size(csvLine[feature_name]) > 0 '
	#	'	WITH '
	#	'		record_type, '
	#	'		field, item, feature, item_level.name_lower as level, '
	#	'		person, time, start, end, replicate, '
	#	'		csvLine[feature_name] as value, '
	#	# these are unique to table uploads, also probably not necessary
	#	# but allows differentiation of defaulted time from set time
	#	' 		csvLine.time as text_time, '
	#	'		csvLine.date as text_date, '
	#	'		csvLine.`start date` as text_start_date, '
	#	'		csvLine.`start time` as text_start_time, '
	#	'		csvLine.`end date` as text_end_date, '
	#	'		csvLine.`end time` as text_end_time, '
	#	# the following are null where FB has values to allow shared code between formats
	#	'		null as timestamp, '
	#	'		null as location '
	#	# for trait data if no time is set then drop the row
	#	# for condition data we allow null time but need to check is this type
	#	# by looking for one of the relevant fields e.g. `start date`
	#	' 		WHERE '
	#	'			CASE '
	#	'			WHEN record_type = "trait" THEN time '
	#	'			ELSE True END '
	#	'			IS NOT NULL '
	#	+ shared_upload_code
	#)

	get_fields_treecount = (
		' MATCH (country:Country)<-[:IS_IN]-(region: Region) '
		' OPTIONAL MATCH (region)<-[:IS_IN]-(farm: Farm) '
		' OPTIONAL MATCH (farm)<-[:IS_IN]-(field: Field) '
		' OPTIONAL MATCH '
		'	(field)'
		'	<-[:IS_IN]-(:FieldTrees)'
		'	<-[:FOR]-(field_tree_counter:Counter {name:"tree"}) '
		' OPTIONAL MATCH '
		'	(field)'
		'	<-[:IS_IN*2]-(block:Block)'
		'	<-[:IS_IN]-(:BlockTrees)'
		'	<-[:FOR]-(block_tree_counter:Counter {name:"tree"}) '
		' WITH '
		'	country, '
		'	region, '
		'	farm, '
		'	field, '
		'	field_tree_counter.count as field_trees, '
		'	{'
		'		name: block.name, '
		'		label:"Block", '
		'		treecount: block_tree_counter.count '
		'	} as blocks, '
		'	block_tree_counter.count as block_trees '
		' WITH '
		'	country, '
		'	region, '
		'	farm, '
		'	{ '
		'		name: field.name, '
		'		label:"Field", '
		'		treecount: field_trees - sum(block_trees), '
		'		children: FILTER(block IN collect(blocks) WHERE block["name"] IS NOT NULL)'
		'	} as fields '
		' WITH '
		'	country, '
		'	region, '
		'	{'
		'		name: farm.name, '
		'		label: "Farm", '
		'		children: FILTER(field IN collect(fields) WHERE field["name"] IS NOT NULL)'
		'	} as farms '
		' WITH '
		'	country, '
		'	{'
		'		name: region.name, '
		'		label:"Region", '
		'		children: FILTER(farm IN collect(farms) WHERE farm["name"] IS NOT NULL)'
		'	} as regions '
		' WITH '
		'	{'
		'		name: country.name, '
		'		label:"Country", '
		'		children: FILTER(region IN collect (regions) WHERE region["name"] IS NOT NULL)'
		'	} as countries '
		' RETURN countries '
	)
	get_submissions_range = (
		# first get all the data collections and link to a base node formed from block/field/farm
		' MATCH '
		'	(:User {username_lower: toLower($username)}) '
		'		-[:SUBMITTED*3]->(:UserFieldFeature) '
		'		-[s:SUBMITTED]->(record: Record) '
		'		-[:RECORD_FOR]->(if:ItemFeature) '
		'		-[:FOR_FEATURE*..2]->(feature: Feature), '
		'	(if)-[:FOR_ITEM]->(item:Item)'
		' OPTIONAL MATCH '
		'	(if)'
		'	-[:FOR_FEATURE]->(:FieldFeature) '
		'	-[:FROM_FIELD]->(field:Field) '
		' WHERE s.time >= $starttime AND s.time <= $endtime '
		' WITH '
		'	feature, count(record) as record_count, coalesce(field, item) as field '
		' RETURN '
		'	"Feature" as d_label, '
		'	feature.name + " (" + toString(record_count) + ")" as d_name, '
		'	id(field) + "_" + id(feature) as d_id, '
		'	field as n_label, '
		'	field.name as n_name,'
		'	id(field) as n_id, '
		'	"FROM" as r_type, '
		'	id(field) + "_" + id(feature) + "_rel" as r_id, '
		'	id(field) + "_" + id(feature) as r_start, '
		'	id(field) as r_end '
		' UNION '
		# get users farm context
		' MATCH '
		'	(:User {username_lower: toLower($username)}) '
		'		-[:SUBMITTED*3]->(:UserFieldFeature) '
		'		-[:CONTRIBUTED]->(: FieldFeature) '
		'		-[:FOR_ITEM | FROM_FIELD]->(field:Field) '
		'		-[:IS_IN]->(farm:Farm) '
		' RETURN '
		'	"Field" as d_label, '
		'	field.name as d_name, '
		'	id(field) as d_id, '
		'	"Farm" as n_label, '
		'	farm.name as n_name, '
		'	id(farm) as n_id, '
		'	"IS_IN" as r_type,  '
		'	(id(field) + "_" + id(farm)) as r_id, '
		'	id(field) as r_start, '
		'	id(farm) as r_end'
		'	UNION '
		# link the above into region context
		' MATCH '
		'	(:User {username_lower: toLower($username)}) '
		'		-[:SUBMITTED*3]->(:UserFieldFeature) '
		'		-[:CONTRIBUTED]->(: FieldFeature) '
		'		-[:FOR_ITEM | FROM_FIELD]->(:Field) '
		'		-[:IS_IN]->(farm: Farm) '
		'		-[:IS_IN]->(region: Region) '
		' RETURN '
			' "Farm" as d_label, '
			' farm.name as d_name, '
			' id(farm) as d_id, '
			' "Region" as n_label, '
			' region.name as n_name, '
			' id(region) as n_id, '
			' "IS_IN" as r_type,  '
			' (id(farm) + "_" + id(region)) as r_id, '
			' id(farm) as r_start, '
			' id(region) as r_end'
		' UNION '
		# link the above into country context
		' MATCH '
		'	(:User {username_lower: toLower($username)}) '
		'		-[:SUBMITTED*3]->(:UserFieldFeature) '
		'		-[:CONTRIBUTED]->(: FieldFeature) '
		'		-[:FOR_ITEM | FROM_FIELD]->(: Field) '
		'		-[:IS_IN]->(: Farm) '
		'		-[:IS_IN]->(region: Region) '
		'		-[:IS_IN]->(country: Country) '
		' RETURN '
			' "Region" as d_label, '
			' region.name as d_name, '
			' id(region) as d_id, '
			' "Country" as n_label, '
			' country.name as n_name, '
			' id(country) as n_id, '
			' "IS_IN" as r_type,  '
			' (id(region) + "_" + id(country)) as r_id, '
			' id(region) as r_start, '
			' id(country) as r_end'
	)
